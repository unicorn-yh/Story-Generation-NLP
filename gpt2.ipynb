{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, PreTrainedTokenizer, GPT2LMHeadModel\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for tokenizing the text and storing it in files is imported here\n",
    "def tokenize_longform_text(raw_text_paths: list,\n",
    "                           tokenizer: PreTrainedTokenizer,\n",
    "                           block_size: int,\n",
    "                           drop_last=True,\n",
    "                           overlap=True):\n",
    "    \"\"\" Loads raw LONGFORM text from a list of paths to text files, tokenizes it, splits the tokenized\n",
    "     text into training examples and returns the list. Requires passing in a HuggingFace Transformers\n",
    "     pretrained tokenizer\"\"\"\n",
    "\n",
    "    # TODO: Look into methods of text augmentation, put this in as a placeholder\n",
    "\n",
    "    # find correct block size of the tokenizer\n",
    "    block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n",
    "\n",
    "    # check that all the text file paths actually files\n",
    "    for text_file in raw_text_paths:\n",
    "        assert os.path.isfile(text_file), \"{} is not a file\".format(text_file)\n",
    "\n",
    "    # make empty list to store all the examples\n",
    "    examples = []\n",
    "\n",
    "    # loop over all text files\n",
    "    for text_file in raw_text_paths:\n",
    "\n",
    "        with open(text_file, encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "                print(\"{} successfully read and tokenized\".format(text_file))\n",
    "            except:\n",
    "                print(\"Error reading or tokenizing file {}\".format(text_file))\n",
    "\n",
    "        # check that the tokenized file is at least one block size long\n",
    "        len_tokens = len(tokenized_text)\n",
    "        print(len_tokens)\n",
    "        if len_tokens < block_size:\n",
    "            print(\"File {} is too short for the block size\".format(text_file))\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            if overlap is False:\n",
    "                for i in range(0, len_tokens - block_size + 1, block_size):  # don't overlap examples\n",
    "                    examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i:i + block_size]))\n",
    "            else:  # overlap examples\n",
    "                for i in range(0, len_tokens - block_size + 1, int(block_size / 2)):\n",
    "                    examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i:i + block_size]))\n",
    "\n",
    "            if drop_last is False:\n",
    "                examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[-block_size:]))\n",
    "\n",
    "            print(\"Successfully split tokens from file {} into examples\".format(text_file))\n",
    "        except:\n",
    "            print(\"Failed at splitting tokens from file {} into examples\".format(text_file))\n",
    "\n",
    "    print(\"{} examples total tokenized\".format(len(examples)))\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenized_examples(tokenizer: PreTrainedTokenizer,\n",
    "                            block_size: int,\n",
    "                            root_dir_path: str,\n",
    "                            examples_file=None):\n",
    "    \"\"\"Tokenize a directory of text where the raw text is in a subdirectory '/raw_text' and the default\n",
    "    is to put the tokenized text into a sub directory '/tokenized_examples' \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Do a bunch of error checking, finding text files and making output file names\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # check that root_dir_path is actually a path\n",
    "    assert os.path.isdir(root_dir_path), \"{} is not a directory\".format(root_dir_path)\n",
    "    # and check that we didn't accidentally put a / at the end of the dir path\n",
    "    if not os.path.split(root_dir_path)[1]:\n",
    "        root_dir_path = os.path.split(root_dir_path)[0]\n",
    "\n",
    "    # check that there is a raw_text directory\n",
    "    raw_dir_path = os.path.join(root_dir_path, \"raw_text\")\n",
    "    assert os.path.isdir(raw_dir_path), \"{} has no raw_text/ subdirectory\".format(root_dir_path)\n",
    "\n",
    "    # check that there are text files in there and if so get their names\n",
    "    file_list = []\n",
    "    for file in os.listdir(raw_dir_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_list.append(os.path.join(raw_dir_path, file))\n",
    "    if len(file_list) == 0:\n",
    "        raise RuntimeError(\"No text files found in {}\".format(raw_dir_path))\n",
    "\n",
    "    # now get the tokenized text file name, make the tokenized_text directory if necessary\n",
    "\n",
    "    if examples_file is None:\n",
    "        tokenized_dir = os.path.join(root_dir_path, \"tokenized_examples\")\n",
    "        if not os.path.isdir(tokenized_dir):\n",
    "            os.mkdir(tokenized_dir)\n",
    "\n",
    "        print(root_dir_path)\n",
    "        print(os.path.split(root_dir_path))\n",
    "\n",
    "        author_name = os.path.split(root_dir_path)[1]\n",
    "        examples_file = \"examples_gpt2_blocksize_{}_{}.pkl\".format(block_size, author_name)\n",
    "        examples_file = os.path.join(tokenized_dir, examples_file)\n",
    "\n",
    "    else:\n",
    "        assert type(examples_file) is str, \"tokenized_file_name must be a string or None\"\n",
    "        tokenized_dir = os.path.split(examples_file)[0]\n",
    "        assert os.path.isdir(tokenized_dir), \"{} is not a directory\".format(tokenized_dir)\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # After all that make the examples and save them\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # tokenize all the files, split them into examples and concatenate them\n",
    "    examples = tokenize_longform_text(file_list, tokenizer, block_size, drop_last=False, overlap=True)\n",
    "\n",
    "    # save them as a pickle\n",
    "    with open(examples_file, 'wb') as f:\n",
    "        pickle.dump(examples, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(\"{} examples created and saved in {}\".format(len(examples), examples_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "train_stories = pd.read_csv(\"story_generation_dataset/ROCStories_train.csv\", encoding=\"utf8\")\n",
    "test_stories = pd.read_csv(\"story_generation_dataset/ROCStories_test.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "for data in train_stories.values[:2000,1:]:\n",
    "    with open(\"data/train/\"+str(index)+\".txt\",\"w\") as file:\n",
    "        for sent in data:\n",
    "            file.write(sent+ r'\\r\\n\\ '[:-1])\n",
    "    file.close()\n",
    "    index += 1\n",
    "\n",
    "index = 1\n",
    "for data in train_stories.values[:500,1:]:\n",
    "    with open(\"data/test/\"+str(index)+\".txt\",\"w\") as file:\n",
    "        for sent in data:\n",
    "            file.write(sent+ r'\\r\\n\\ '[:-1])\n",
    "    file.close()\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.04M/1.04M [00:01<00:00, 779kB/s]\n",
      "d:\\Downloads\\Python3.7\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ACER\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 456k/456k [00:01<00:00, 365kB/s]  \n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 84.1kB/s]\n"
     ]
    }
   ],
   "source": [
    "# import the tokenizer from the Transformers library\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/'\n",
    "test_path = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train\n",
      "('data', 'train')\n",
      "data/train\\raw_text\\1.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1.txt into examples\n",
      "data/train\\raw_text\\10.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\10.txt into examples\n",
      "data/train\\raw_text\\100.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\100.txt into examples\n",
      "data/train\\raw_text\\1000.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1000.txt into examples\n",
      "data/train\\raw_text\\1001.txt successfully read and tokenized\n",
      "32\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1001.txt into examples\n",
      "data/train\\raw_text\\1002.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1002.txt into examples\n",
      "data/train\\raw_text\\1003.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1003.txt into examples\n",
      "data/train\\raw_text\\1004.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1004.txt into examples\n",
      "data/train\\raw_text\\1005.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1005.txt into examples\n",
      "data/train\\raw_text\\1006.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1006.txt into examples\n",
      "data/train\\raw_text\\1007.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1007.txt into examples\n",
      "data/train\\raw_text\\1008.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1008.txt into examples\n",
      "data/train\\raw_text\\1009.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1009.txt into examples\n",
      "data/train\\raw_text\\101.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\101.txt into examples\n",
      "data/train\\raw_text\\1010.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1010.txt into examples\n",
      "data/train\\raw_text\\1011.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1011.txt into examples\n",
      "data/train\\raw_text\\1012.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1012.txt into examples\n",
      "data/train\\raw_text\\1013.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1013.txt into examples\n",
      "data/train\\raw_text\\1014.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1014.txt into examples\n",
      "data/train\\raw_text\\1015.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1015.txt into examples\n",
      "data/train\\raw_text\\1016.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1016.txt into examples\n",
      "data/train\\raw_text\\1017.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1017.txt into examples\n",
      "data/train\\raw_text\\1018.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1018.txt into examples\n",
      "data/train\\raw_text\\1019.txt successfully read and tokenized\n",
      "83\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1019.txt into examples\n",
      "data/train\\raw_text\\102.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\102.txt into examples\n",
      "data/train\\raw_text\\1020.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1020.txt into examples\n",
      "data/train\\raw_text\\1021.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1021.txt into examples\n",
      "data/train\\raw_text\\1022.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1022.txt into examples\n",
      "data/train\\raw_text\\1023.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1023.txt into examples\n",
      "data/train\\raw_text\\1024.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1024.txt into examples\n",
      "data/train\\raw_text\\1025.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1025.txt into examples\n",
      "data/train\\raw_text\\1026.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1026.txt into examples\n",
      "data/train\\raw_text\\1027.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1027.txt into examples\n",
      "data/train\\raw_text\\1028.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1028.txt into examples\n",
      "data/train\\raw_text\\1029.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1029.txt into examples\n",
      "data/train\\raw_text\\103.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\103.txt into examples\n",
      "data/train\\raw_text\\1030.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1030.txt into examples\n",
      "data/train\\raw_text\\1031.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1031.txt into examples\n",
      "data/train\\raw_text\\1032.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1032.txt into examples\n",
      "data/train\\raw_text\\1033.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1033.txt into examples\n",
      "data/train\\raw_text\\1034.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1034.txt into examples\n",
      "data/train\\raw_text\\1035.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1035.txt into examples\n",
      "data/train\\raw_text\\1036.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1036.txt into examples\n",
      "data/train\\raw_text\\1037.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1037.txt into examples\n",
      "data/train\\raw_text\\1038.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1038.txt into examples\n",
      "data/train\\raw_text\\1039.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1039.txt into examples\n",
      "data/train\\raw_text\\104.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\104.txt into examples\n",
      "data/train\\raw_text\\1040.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1040.txt into examples\n",
      "data/train\\raw_text\\1041.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1041.txt into examples\n",
      "data/train\\raw_text\\1042.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1042.txt into examples\n",
      "data/train\\raw_text\\1043.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1043.txt into examples\n",
      "data/train\\raw_text\\1044.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1044.txt into examples\n",
      "data/train\\raw_text\\1045.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1045.txt into examples\n",
      "data/train\\raw_text\\1046.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1046.txt into examples\n",
      "data/train\\raw_text\\1047.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1047.txt into examples\n",
      "data/train\\raw_text\\1048.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1048.txt into examples\n",
      "data/train\\raw_text\\1049.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1049.txt into examples\n",
      "data/train\\raw_text\\105.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\105.txt into examples\n",
      "data/train\\raw_text\\1050.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1050.txt into examples\n",
      "data/train\\raw_text\\1051.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1051.txt into examples\n",
      "data/train\\raw_text\\1052.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1052.txt into examples\n",
      "data/train\\raw_text\\1053.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1053.txt into examples\n",
      "data/train\\raw_text\\1054.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1054.txt into examples\n",
      "data/train\\raw_text\\1055.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1055.txt into examples\n",
      "data/train\\raw_text\\1056.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1056.txt into examples\n",
      "data/train\\raw_text\\1057.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1057.txt into examples\n",
      "data/train\\raw_text\\1058.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1058.txt into examples\n",
      "data/train\\raw_text\\1059.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1059.txt into examples\n",
      "data/train\\raw_text\\106.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\106.txt into examples\n",
      "data/train\\raw_text\\1060.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1060.txt into examples\n",
      "data/train\\raw_text\\1061.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1061.txt into examples\n",
      "data/train\\raw_text\\1062.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1062.txt into examples\n",
      "data/train\\raw_text\\1063.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1063.txt into examples\n",
      "data/train\\raw_text\\1064.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1064.txt into examples\n",
      "data/train\\raw_text\\1065.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1065.txt into examples\n",
      "data/train\\raw_text\\1066.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1066.txt into examples\n",
      "data/train\\raw_text\\1067.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1067.txt into examples\n",
      "data/train\\raw_text\\1068.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1068.txt into examples\n",
      "data/train\\raw_text\\1069.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1069.txt into examples\n",
      "data/train\\raw_text\\107.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\107.txt into examples\n",
      "data/train\\raw_text\\1070.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1070.txt into examples\n",
      "data/train\\raw_text\\1071.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1071.txt into examples\n",
      "data/train\\raw_text\\1072.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1072.txt into examples\n",
      "data/train\\raw_text\\1073.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1073.txt into examples\n",
      "data/train\\raw_text\\1074.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1074.txt into examples\n",
      "data/train\\raw_text\\1075.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1075.txt into examples\n",
      "data/train\\raw_text\\1076.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1076.txt into examples\n",
      "data/train\\raw_text\\1077.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1077.txt into examples\n",
      "data/train\\raw_text\\1078.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1078.txt into examples\n",
      "data/train\\raw_text\\1079.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1079.txt into examples\n",
      "data/train\\raw_text\\108.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\108.txt into examples\n",
      "data/train\\raw_text\\1080.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1080.txt into examples\n",
      "data/train\\raw_text\\1081.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1081.txt into examples\n",
      "data/train\\raw_text\\1082.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1082.txt into examples\n",
      "data/train\\raw_text\\1083.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1083.txt into examples\n",
      "data/train\\raw_text\\1084.txt successfully read and tokenized\n",
      "80\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1084.txt into examples\n",
      "data/train\\raw_text\\1085.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1085.txt into examples\n",
      "data/train\\raw_text\\1086.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1086.txt into examples\n",
      "data/train\\raw_text\\1087.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1087.txt into examples\n",
      "data/train\\raw_text\\1088.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1088.txt into examples\n",
      "data/train\\raw_text\\1089.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1089.txt into examples\n",
      "data/train\\raw_text\\109.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\109.txt into examples\n",
      "data/train\\raw_text\\1090.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1090.txt into examples\n",
      "data/train\\raw_text\\1091.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1091.txt into examples\n",
      "data/train\\raw_text\\1092.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1092.txt into examples\n",
      "data/train\\raw_text\\1093.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1093.txt into examples\n",
      "data/train\\raw_text\\1094.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1094.txt into examples\n",
      "data/train\\raw_text\\1095.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1095.txt into examples\n",
      "data/train\\raw_text\\1096.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1096.txt into examples\n",
      "data/train\\raw_text\\1097.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1097.txt into examples\n",
      "data/train\\raw_text\\1098.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1098.txt into examples\n",
      "data/train\\raw_text\\1099.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1099.txt into examples\n",
      "data/train\\raw_text\\11.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\11.txt into examples\n",
      "data/train\\raw_text\\110.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\110.txt into examples\n",
      "data/train\\raw_text\\1100.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1100.txt into examples\n",
      "data/train\\raw_text\\1101.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1101.txt into examples\n",
      "data/train\\raw_text\\1102.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1102.txt into examples\n",
      "data/train\\raw_text\\1103.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1103.txt into examples\n",
      "data/train\\raw_text\\1104.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1104.txt into examples\n",
      "data/train\\raw_text\\1105.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1105.txt into examples\n",
      "data/train\\raw_text\\1106.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1106.txt into examples\n",
      "data/train\\raw_text\\1107.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1107.txt into examples\n",
      "data/train\\raw_text\\1108.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1108.txt into examples\n",
      "data/train\\raw_text\\1109.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1109.txt into examples\n",
      "data/train\\raw_text\\111.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\111.txt into examples\n",
      "data/train\\raw_text\\1110.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1110.txt into examples\n",
      "data/train\\raw_text\\1111.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1111.txt into examples\n",
      "data/train\\raw_text\\1112.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1112.txt into examples\n",
      "data/train\\raw_text\\1113.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1113.txt into examples\n",
      "data/train\\raw_text\\1114.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1114.txt into examples\n",
      "data/train\\raw_text\\1115.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1115.txt into examples\n",
      "data/train\\raw_text\\1116.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1116.txt into examples\n",
      "data/train\\raw_text\\1117.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1117.txt into examples\n",
      "data/train\\raw_text\\1118.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1118.txt into examples\n",
      "data/train\\raw_text\\1119.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1119.txt into examples\n",
      "data/train\\raw_text\\112.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\112.txt into examples\n",
      "data/train\\raw_text\\1120.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1120.txt into examples\n",
      "data/train\\raw_text\\1121.txt successfully read and tokenized\n",
      "82\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1121.txt into examples\n",
      "data/train\\raw_text\\1122.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1122.txt into examples\n",
      "data/train\\raw_text\\1123.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1123.txt into examples\n",
      "data/train\\raw_text\\1124.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1124.txt into examples\n",
      "data/train\\raw_text\\1125.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1125.txt into examples\n",
      "data/train\\raw_text\\1126.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1126.txt into examples\n",
      "data/train\\raw_text\\1127.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1127.txt into examples\n",
      "data/train\\raw_text\\1128.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1128.txt into examples\n",
      "data/train\\raw_text\\1129.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1129.txt into examples\n",
      "data/train\\raw_text\\113.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\113.txt into examples\n",
      "data/train\\raw_text\\1130.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1130.txt into examples\n",
      "data/train\\raw_text\\1131.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1131.txt into examples\n",
      "data/train\\raw_text\\1132.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1132.txt into examples\n",
      "data/train\\raw_text\\1133.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1133.txt into examples\n",
      "data/train\\raw_text\\1134.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1134.txt into examples\n",
      "data/train\\raw_text\\1135.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1135.txt into examples\n",
      "data/train\\raw_text\\1136.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1136.txt into examples\n",
      "data/train\\raw_text\\1137.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1137.txt into examples\n",
      "data/train\\raw_text\\1138.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1138.txt into examples\n",
      "data/train\\raw_text\\1139.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1139.txt into examples\n",
      "data/train\\raw_text\\114.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\114.txt into examples\n",
      "data/train\\raw_text\\1140.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1140.txt into examples\n",
      "data/train\\raw_text\\1141.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1141.txt into examples\n",
      "data/train\\raw_text\\1142.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1142.txt into examples\n",
      "data/train\\raw_text\\1143.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1143.txt into examples\n",
      "data/train\\raw_text\\1144.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1144.txt into examples\n",
      "data/train\\raw_text\\1145.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1145.txt into examples\n",
      "data/train\\raw_text\\1146.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1146.txt into examples\n",
      "data/train\\raw_text\\1147.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1147.txt into examples\n",
      "data/train\\raw_text\\1148.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1148.txt into examples\n",
      "data/train\\raw_text\\1149.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1149.txt into examples\n",
      "data/train\\raw_text\\115.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\115.txt into examples\n",
      "data/train\\raw_text\\1150.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1150.txt into examples\n",
      "data/train\\raw_text\\1151.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1151.txt into examples\n",
      "data/train\\raw_text\\1152.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1152.txt into examples\n",
      "data/train\\raw_text\\1153.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1153.txt into examples\n",
      "data/train\\raw_text\\1154.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1154.txt into examples\n",
      "data/train\\raw_text\\1155.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1155.txt into examples\n",
      "data/train\\raw_text\\1156.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1156.txt into examples\n",
      "data/train\\raw_text\\1157.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1157.txt into examples\n",
      "data/train\\raw_text\\1158.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1158.txt into examples\n",
      "data/train\\raw_text\\1159.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1159.txt into examples\n",
      "data/train\\raw_text\\116.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\116.txt into examples\n",
      "data/train\\raw_text\\1160.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1160.txt into examples\n",
      "data/train\\raw_text\\1161.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1161.txt into examples\n",
      "data/train\\raw_text\\1162.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1162.txt into examples\n",
      "data/train\\raw_text\\1163.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1163.txt into examples\n",
      "data/train\\raw_text\\1164.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1164.txt into examples\n",
      "data/train\\raw_text\\1165.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1165.txt into examples\n",
      "data/train\\raw_text\\1166.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1166.txt into examples\n",
      "data/train\\raw_text\\1167.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1167.txt into examples\n",
      "data/train\\raw_text\\1168.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1168.txt into examples\n",
      "data/train\\raw_text\\1169.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1169.txt into examples\n",
      "data/train\\raw_text\\117.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\117.txt into examples\n",
      "data/train\\raw_text\\1170.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1170.txt into examples\n",
      "data/train\\raw_text\\1171.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1171.txt into examples\n",
      "data/train\\raw_text\\1172.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1172.txt into examples\n",
      "data/train\\raw_text\\1173.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1173.txt into examples\n",
      "data/train\\raw_text\\1174.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1174.txt into examples\n",
      "data/train\\raw_text\\1175.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1175.txt into examples\n",
      "data/train\\raw_text\\1176.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1176.txt into examples\n",
      "data/train\\raw_text\\1177.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1177.txt into examples\n",
      "data/train\\raw_text\\1178.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1178.txt into examples\n",
      "data/train\\raw_text\\1179.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1179.txt into examples\n",
      "data/train\\raw_text\\118.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\118.txt into examples\n",
      "data/train\\raw_text\\1180.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1180.txt into examples\n",
      "data/train\\raw_text\\1181.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1181.txt into examples\n",
      "data/train\\raw_text\\1182.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1182.txt into examples\n",
      "data/train\\raw_text\\1183.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1183.txt into examples\n",
      "data/train\\raw_text\\1184.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1184.txt into examples\n",
      "data/train\\raw_text\\1185.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1185.txt into examples\n",
      "data/train\\raw_text\\1186.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1186.txt into examples\n",
      "data/train\\raw_text\\1187.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1187.txt into examples\n",
      "data/train\\raw_text\\1188.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1188.txt into examples\n",
      "data/train\\raw_text\\1189.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1189.txt into examples\n",
      "data/train\\raw_text\\119.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\119.txt into examples\n",
      "data/train\\raw_text\\1190.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1190.txt into examples\n",
      "data/train\\raw_text\\1191.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1191.txt into examples\n",
      "data/train\\raw_text\\1192.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1192.txt into examples\n",
      "data/train\\raw_text\\1193.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1193.txt into examples\n",
      "data/train\\raw_text\\1194.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1194.txt into examples\n",
      "data/train\\raw_text\\1195.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1195.txt into examples\n",
      "data/train\\raw_text\\1196.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1196.txt into examples\n",
      "data/train\\raw_text\\1197.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1197.txt into examples\n",
      "data/train\\raw_text\\1198.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1198.txt into examples\n",
      "data/train\\raw_text\\1199.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1199.txt into examples\n",
      "data/train\\raw_text\\12.txt successfully read and tokenized\n",
      "33\n",
      "Failed at splitting tokens from file data/train\\raw_text\\12.txt into examples\n",
      "data/train\\raw_text\\120.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\120.txt into examples\n",
      "data/train\\raw_text\\1200.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1200.txt into examples\n",
      "data/train\\raw_text\\1201.txt successfully read and tokenized\n",
      "76\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1201.txt into examples\n",
      "data/train\\raw_text\\1202.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1202.txt into examples\n",
      "data/train\\raw_text\\1203.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1203.txt into examples\n",
      "data/train\\raw_text\\1204.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1204.txt into examples\n",
      "data/train\\raw_text\\1205.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1205.txt into examples\n",
      "data/train\\raw_text\\1206.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1206.txt into examples\n",
      "data/train\\raw_text\\1207.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1207.txt into examples\n",
      "data/train\\raw_text\\1208.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1208.txt into examples\n",
      "data/train\\raw_text\\1209.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1209.txt into examples\n",
      "data/train\\raw_text\\121.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\121.txt into examples\n",
      "data/train\\raw_text\\1210.txt successfully read and tokenized\n",
      "32\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1210.txt into examples\n",
      "data/train\\raw_text\\1211.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1211.txt into examples\n",
      "data/train\\raw_text\\1212.txt successfully read and tokenized\n",
      "36\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1212.txt into examples\n",
      "data/train\\raw_text\\1213.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1213.txt into examples\n",
      "data/train\\raw_text\\1214.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1214.txt into examples\n",
      "data/train\\raw_text\\1215.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1215.txt into examples\n",
      "data/train\\raw_text\\1216.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1216.txt into examples\n",
      "data/train\\raw_text\\1217.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1217.txt into examples\n",
      "data/train\\raw_text\\1218.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1218.txt into examples\n",
      "data/train\\raw_text\\1219.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1219.txt into examples\n",
      "data/train\\raw_text\\122.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\122.txt into examples\n",
      "data/train\\raw_text\\1220.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1220.txt into examples\n",
      "data/train\\raw_text\\1221.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1221.txt into examples\n",
      "data/train\\raw_text\\1222.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1222.txt into examples\n",
      "data/train\\raw_text\\1223.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1223.txt into examples\n",
      "data/train\\raw_text\\1224.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1224.txt into examples\n",
      "data/train\\raw_text\\1225.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1225.txt into examples\n",
      "data/train\\raw_text\\1226.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1226.txt into examples\n",
      "data/train\\raw_text\\1227.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1227.txt into examples\n",
      "data/train\\raw_text\\1228.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1228.txt into examples\n",
      "data/train\\raw_text\\1229.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1229.txt into examples\n",
      "data/train\\raw_text\\123.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\123.txt into examples\n",
      "data/train\\raw_text\\1230.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1230.txt into examples\n",
      "data/train\\raw_text\\1231.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1231.txt into examples\n",
      "data/train\\raw_text\\1232.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1232.txt into examples\n",
      "data/train\\raw_text\\1233.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1233.txt into examples\n",
      "data/train\\raw_text\\1234.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1234.txt into examples\n",
      "data/train\\raw_text\\1235.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1235.txt into examples\n",
      "data/train\\raw_text\\1236.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1236.txt into examples\n",
      "data/train\\raw_text\\1237.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1237.txt into examples\n",
      "data/train\\raw_text\\1238.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1238.txt into examples\n",
      "data/train\\raw_text\\1239.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1239.txt into examples\n",
      "data/train\\raw_text\\124.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\124.txt into examples\n",
      "data/train\\raw_text\\1240.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1240.txt into examples\n",
      "data/train\\raw_text\\1241.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1241.txt into examples\n",
      "data/train\\raw_text\\1242.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1242.txt into examples\n",
      "data/train\\raw_text\\1243.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1243.txt into examples\n",
      "data/train\\raw_text\\1244.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1244.txt into examples\n",
      "data/train\\raw_text\\1245.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1245.txt into examples\n",
      "data/train\\raw_text\\1246.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1246.txt into examples\n",
      "data/train\\raw_text\\1247.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1247.txt into examples\n",
      "data/train\\raw_text\\1248.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1248.txt into examples\n",
      "data/train\\raw_text\\1249.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1249.txt into examples\n",
      "data/train\\raw_text\\125.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\125.txt into examples\n",
      "data/train\\raw_text\\1250.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1250.txt into examples\n",
      "data/train\\raw_text\\1251.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1251.txt into examples\n",
      "data/train\\raw_text\\1252.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1252.txt into examples\n",
      "data/train\\raw_text\\1253.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1253.txt into examples\n",
      "data/train\\raw_text\\1254.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1254.txt into examples\n",
      "data/train\\raw_text\\1255.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1255.txt into examples\n",
      "data/train\\raw_text\\1256.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1256.txt into examples\n",
      "data/train\\raw_text\\1257.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1257.txt into examples\n",
      "data/train\\raw_text\\1258.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1258.txt into examples\n",
      "data/train\\raw_text\\1259.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1259.txt into examples\n",
      "data/train\\raw_text\\126.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\126.txt into examples\n",
      "data/train\\raw_text\\1260.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1260.txt into examples\n",
      "data/train\\raw_text\\1261.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1261.txt into examples\n",
      "data/train\\raw_text\\1262.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1262.txt into examples\n",
      "data/train\\raw_text\\1263.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1263.txt into examples\n",
      "data/train\\raw_text\\1264.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1264.txt into examples\n",
      "data/train\\raw_text\\1265.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1265.txt into examples\n",
      "data/train\\raw_text\\1266.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1266.txt into examples\n",
      "data/train\\raw_text\\1267.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1267.txt into examples\n",
      "data/train\\raw_text\\1268.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1268.txt into examples\n",
      "data/train\\raw_text\\1269.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1269.txt into examples\n",
      "data/train\\raw_text\\127.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\127.txt into examples\n",
      "data/train\\raw_text\\1270.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1270.txt into examples\n",
      "data/train\\raw_text\\1271.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1271.txt into examples\n",
      "data/train\\raw_text\\1272.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1272.txt into examples\n",
      "data/train\\raw_text\\1273.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1273.txt into examples\n",
      "data/train\\raw_text\\1274.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1274.txt into examples\n",
      "data/train\\raw_text\\1275.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1275.txt into examples\n",
      "data/train\\raw_text\\1276.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1276.txt into examples\n",
      "data/train\\raw_text\\1277.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1277.txt into examples\n",
      "data/train\\raw_text\\1278.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1278.txt into examples\n",
      "data/train\\raw_text\\1279.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1279.txt into examples\n",
      "data/train\\raw_text\\128.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\128.txt into examples\n",
      "data/train\\raw_text\\1280.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1280.txt into examples\n",
      "data/train\\raw_text\\1281.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1281.txt into examples\n",
      "data/train\\raw_text\\1282.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1282.txt into examples\n",
      "data/train\\raw_text\\1283.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1283.txt into examples\n",
      "data/train\\raw_text\\1284.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1284.txt into examples\n",
      "data/train\\raw_text\\1285.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1285.txt into examples\n",
      "data/train\\raw_text\\1286.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1286.txt into examples\n",
      "data/train\\raw_text\\1287.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1287.txt into examples\n",
      "data/train\\raw_text\\1288.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1288.txt into examples\n",
      "data/train\\raw_text\\1289.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1289.txt into examples\n",
      "data/train\\raw_text\\129.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\129.txt into examples\n",
      "data/train\\raw_text\\1290.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1290.txt into examples\n",
      "data/train\\raw_text\\1291.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1291.txt into examples\n",
      "data/train\\raw_text\\1292.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1292.txt into examples\n",
      "data/train\\raw_text\\1293.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1293.txt into examples\n",
      "data/train\\raw_text\\1294.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1294.txt into examples\n",
      "data/train\\raw_text\\1295.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1295.txt into examples\n",
      "data/train\\raw_text\\1296.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1296.txt into examples\n",
      "data/train\\raw_text\\1297.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1297.txt into examples\n",
      "data/train\\raw_text\\1298.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1298.txt into examples\n",
      "data/train\\raw_text\\1299.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1299.txt into examples\n",
      "data/train\\raw_text\\13.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\13.txt into examples\n",
      "data/train\\raw_text\\130.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\130.txt into examples\n",
      "data/train\\raw_text\\1300.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1300.txt into examples\n",
      "data/train\\raw_text\\1301.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1301.txt into examples\n",
      "data/train\\raw_text\\1302.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1302.txt into examples\n",
      "data/train\\raw_text\\1303.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1303.txt into examples\n",
      "data/train\\raw_text\\1304.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1304.txt into examples\n",
      "data/train\\raw_text\\1305.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1305.txt into examples\n",
      "data/train\\raw_text\\1306.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1306.txt into examples\n",
      "data/train\\raw_text\\1307.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1307.txt into examples\n",
      "data/train\\raw_text\\1308.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1308.txt into examples\n",
      "data/train\\raw_text\\1309.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1309.txt into examples\n",
      "data/train\\raw_text\\131.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\131.txt into examples\n",
      "data/train\\raw_text\\1310.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1310.txt into examples\n",
      "data/train\\raw_text\\1311.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1311.txt into examples\n",
      "data/train\\raw_text\\1312.txt successfully read and tokenized\n",
      "78\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1312.txt into examples\n",
      "data/train\\raw_text\\1313.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1313.txt into examples\n",
      "data/train\\raw_text\\1314.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1314.txt into examples\n",
      "data/train\\raw_text\\1315.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1315.txt into examples\n",
      "data/train\\raw_text\\1316.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1316.txt into examples\n",
      "data/train\\raw_text\\1317.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1317.txt into examples\n",
      "data/train\\raw_text\\1318.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1318.txt into examples\n",
      "data/train\\raw_text\\1319.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1319.txt into examples\n",
      "data/train\\raw_text\\132.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\132.txt into examples\n",
      "data/train\\raw_text\\1320.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1320.txt into examples\n",
      "data/train\\raw_text\\1321.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1321.txt into examples\n",
      "data/train\\raw_text\\1322.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1322.txt into examples\n",
      "data/train\\raw_text\\1323.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1323.txt into examples\n",
      "data/train\\raw_text\\1324.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1324.txt into examples\n",
      "data/train\\raw_text\\1325.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1325.txt into examples\n",
      "data/train\\raw_text\\1326.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1326.txt into examples\n",
      "data/train\\raw_text\\1327.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1327.txt into examples\n",
      "data/train\\raw_text\\1328.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1328.txt into examples\n",
      "data/train\\raw_text\\1329.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1329.txt into examples\n",
      "data/train\\raw_text\\133.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\133.txt into examples\n",
      "data/train\\raw_text\\1330.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1330.txt into examples\n",
      "data/train\\raw_text\\1331.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1331.txt into examples\n",
      "data/train\\raw_text\\1332.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1332.txt into examples\n",
      "data/train\\raw_text\\1333.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1333.txt into examples\n",
      "data/train\\raw_text\\1334.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1334.txt into examples\n",
      "data/train\\raw_text\\1335.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1335.txt into examples\n",
      "data/train\\raw_text\\1336.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1336.txt into examples\n",
      "data/train\\raw_text\\1337.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1337.txt into examples\n",
      "data/train\\raw_text\\1338.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1338.txt into examples\n",
      "data/train\\raw_text\\1339.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1339.txt into examples\n",
      "data/train\\raw_text\\134.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\134.txt into examples\n",
      "data/train\\raw_text\\1340.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1340.txt into examples\n",
      "data/train\\raw_text\\1341.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1341.txt into examples\n",
      "data/train\\raw_text\\1342.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1342.txt into examples\n",
      "data/train\\raw_text\\1343.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1343.txt into examples\n",
      "data/train\\raw_text\\1344.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1344.txt into examples\n",
      "data/train\\raw_text\\1345.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1345.txt into examples\n",
      "data/train\\raw_text\\1346.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1346.txt into examples\n",
      "data/train\\raw_text\\1347.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1347.txt into examples\n",
      "data/train\\raw_text\\1348.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1348.txt into examples\n",
      "data/train\\raw_text\\1349.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1349.txt into examples\n",
      "data/train\\raw_text\\135.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\135.txt into examples\n",
      "data/train\\raw_text\\1350.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1350.txt into examples\n",
      "data/train\\raw_text\\1351.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1351.txt into examples\n",
      "data/train\\raw_text\\1352.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1352.txt into examples\n",
      "data/train\\raw_text\\1353.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1353.txt into examples\n",
      "data/train\\raw_text\\1354.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1354.txt into examples\n",
      "data/train\\raw_text\\1355.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1355.txt into examples\n",
      "data/train\\raw_text\\1356.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1356.txt into examples\n",
      "data/train\\raw_text\\1357.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1357.txt into examples\n",
      "data/train\\raw_text\\1358.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1358.txt into examples\n",
      "data/train\\raw_text\\1359.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1359.txt into examples\n",
      "data/train\\raw_text\\136.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\136.txt into examples\n",
      "data/train\\raw_text\\1360.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1360.txt into examples\n",
      "data/train\\raw_text\\1361.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1361.txt into examples\n",
      "data/train\\raw_text\\1362.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1362.txt into examples\n",
      "data/train\\raw_text\\1363.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1363.txt into examples\n",
      "data/train\\raw_text\\1364.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1364.txt into examples\n",
      "data/train\\raw_text\\1365.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1365.txt into examples\n",
      "data/train\\raw_text\\1366.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1366.txt into examples\n",
      "data/train\\raw_text\\1367.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1367.txt into examples\n",
      "data/train\\raw_text\\1368.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1368.txt into examples\n",
      "data/train\\raw_text\\1369.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1369.txt into examples\n",
      "data/train\\raw_text\\137.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\137.txt into examples\n",
      "data/train\\raw_text\\1370.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1370.txt into examples\n",
      "data/train\\raw_text\\1371.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1371.txt into examples\n",
      "data/train\\raw_text\\1372.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1372.txt into examples\n",
      "data/train\\raw_text\\1373.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1373.txt into examples\n",
      "data/train\\raw_text\\1374.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1374.txt into examples\n",
      "data/train\\raw_text\\1375.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1375.txt into examples\n",
      "data/train\\raw_text\\1376.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1376.txt into examples\n",
      "data/train\\raw_text\\1377.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1377.txt into examples\n",
      "data/train\\raw_text\\1378.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1378.txt into examples\n",
      "data/train\\raw_text\\1379.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1379.txt into examples\n",
      "data/train\\raw_text\\138.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\138.txt into examples\n",
      "data/train\\raw_text\\1380.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1380.txt into examples\n",
      "data/train\\raw_text\\1381.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1381.txt into examples\n",
      "data/train\\raw_text\\1382.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1382.txt into examples\n",
      "data/train\\raw_text\\1383.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1383.txt into examples\n",
      "data/train\\raw_text\\1384.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1384.txt into examples\n",
      "data/train\\raw_text\\1385.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1385.txt into examples\n",
      "data/train\\raw_text\\1386.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1386.txt into examples\n",
      "data/train\\raw_text\\1387.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1387.txt into examples\n",
      "data/train\\raw_text\\1388.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1388.txt into examples\n",
      "data/train\\raw_text\\1389.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1389.txt into examples\n",
      "data/train\\raw_text\\139.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\139.txt into examples\n",
      "data/train\\raw_text\\1390.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1390.txt into examples\n",
      "data/train\\raw_text\\1391.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1391.txt into examples\n",
      "data/train\\raw_text\\1392.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1392.txt into examples\n",
      "data/train\\raw_text\\1393.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1393.txt into examples\n",
      "data/train\\raw_text\\1394.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1394.txt into examples\n",
      "data/train\\raw_text\\1395.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1395.txt into examples\n",
      "data/train\\raw_text\\1396.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1396.txt into examples\n",
      "data/train\\raw_text\\1397.txt successfully read and tokenized\n",
      "39\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1397.txt into examples\n",
      "data/train\\raw_text\\1398.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1398.txt into examples\n",
      "data/train\\raw_text\\1399.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1399.txt into examples\n",
      "data/train\\raw_text\\14.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\14.txt into examples\n",
      "data/train\\raw_text\\140.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\140.txt into examples\n",
      "data/train\\raw_text\\1400.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1400.txt into examples\n",
      "data/train\\raw_text\\1401.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1401.txt into examples\n",
      "data/train\\raw_text\\1402.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1402.txt into examples\n",
      "data/train\\raw_text\\1403.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1403.txt into examples\n",
      "data/train\\raw_text\\1404.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1404.txt into examples\n",
      "data/train\\raw_text\\1405.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1405.txt into examples\n",
      "data/train\\raw_text\\1406.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1406.txt into examples\n",
      "data/train\\raw_text\\1407.txt successfully read and tokenized\n",
      "76\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1407.txt into examples\n",
      "data/train\\raw_text\\1408.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1408.txt into examples\n",
      "data/train\\raw_text\\1409.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1409.txt into examples\n",
      "data/train\\raw_text\\141.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\141.txt into examples\n",
      "data/train\\raw_text\\1410.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1410.txt into examples\n",
      "data/train\\raw_text\\1411.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1411.txt into examples\n",
      "data/train\\raw_text\\1412.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1412.txt into examples\n",
      "data/train\\raw_text\\1413.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1413.txt into examples\n",
      "data/train\\raw_text\\1414.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1414.txt into examples\n",
      "data/train\\raw_text\\1415.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1415.txt into examples\n",
      "data/train\\raw_text\\1416.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1416.txt into examples\n",
      "data/train\\raw_text\\1417.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1417.txt into examples\n",
      "data/train\\raw_text\\1418.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1418.txt into examples\n",
      "data/train\\raw_text\\1419.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1419.txt into examples\n",
      "data/train\\raw_text\\142.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\142.txt into examples\n",
      "data/train\\raw_text\\1420.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1420.txt into examples\n",
      "data/train\\raw_text\\1421.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1421.txt into examples\n",
      "data/train\\raw_text\\1422.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1422.txt into examples\n",
      "data/train\\raw_text\\1423.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1423.txt into examples\n",
      "data/train\\raw_text\\1424.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1424.txt into examples\n",
      "data/train\\raw_text\\1425.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1425.txt into examples\n",
      "data/train\\raw_text\\1426.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1426.txt into examples\n",
      "data/train\\raw_text\\1427.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1427.txt into examples\n",
      "data/train\\raw_text\\1428.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1428.txt into examples\n",
      "data/train\\raw_text\\1429.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1429.txt into examples\n",
      "data/train\\raw_text\\143.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\143.txt into examples\n",
      "data/train\\raw_text\\1430.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1430.txt into examples\n",
      "data/train\\raw_text\\1431.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1431.txt into examples\n",
      "data/train\\raw_text\\1432.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1432.txt into examples\n",
      "data/train\\raw_text\\1433.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1433.txt into examples\n",
      "data/train\\raw_text\\1434.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1434.txt into examples\n",
      "data/train\\raw_text\\1435.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1435.txt into examples\n",
      "data/train\\raw_text\\1436.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1436.txt into examples\n",
      "data/train\\raw_text\\1437.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1437.txt into examples\n",
      "data/train\\raw_text\\1438.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1438.txt into examples\n",
      "data/train\\raw_text\\1439.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1439.txt into examples\n",
      "data/train\\raw_text\\144.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\144.txt into examples\n",
      "data/train\\raw_text\\1440.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1440.txt into examples\n",
      "data/train\\raw_text\\1441.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1441.txt into examples\n",
      "data/train\\raw_text\\1442.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1442.txt into examples\n",
      "data/train\\raw_text\\1443.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1443.txt into examples\n",
      "data/train\\raw_text\\1444.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1444.txt into examples\n",
      "data/train\\raw_text\\1445.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1445.txt into examples\n",
      "data/train\\raw_text\\1446.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1446.txt into examples\n",
      "data/train\\raw_text\\1447.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1447.txt into examples\n",
      "data/train\\raw_text\\1448.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1448.txt into examples\n",
      "data/train\\raw_text\\1449.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1449.txt into examples\n",
      "data/train\\raw_text\\145.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\145.txt into examples\n",
      "data/train\\raw_text\\1450.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1450.txt into examples\n",
      "data/train\\raw_text\\1451.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1451.txt into examples\n",
      "data/train\\raw_text\\1452.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1452.txt into examples\n",
      "data/train\\raw_text\\1453.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1453.txt into examples\n",
      "data/train\\raw_text\\1454.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1454.txt into examples\n",
      "data/train\\raw_text\\1455.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1455.txt into examples\n",
      "data/train\\raw_text\\1456.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1456.txt into examples\n",
      "data/train\\raw_text\\1457.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1457.txt into examples\n",
      "data/train\\raw_text\\1458.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1458.txt into examples\n",
      "data/train\\raw_text\\1459.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1459.txt into examples\n",
      "data/train\\raw_text\\146.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\146.txt into examples\n",
      "data/train\\raw_text\\1460.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1460.txt into examples\n",
      "data/train\\raw_text\\1461.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1461.txt into examples\n",
      "data/train\\raw_text\\1462.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1462.txt into examples\n",
      "data/train\\raw_text\\1463.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1463.txt into examples\n",
      "data/train\\raw_text\\1464.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1464.txt into examples\n",
      "data/train\\raw_text\\1465.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1465.txt into examples\n",
      "data/train\\raw_text\\1466.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1466.txt into examples\n",
      "data/train\\raw_text\\1467.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1467.txt into examples\n",
      "data/train\\raw_text\\1468.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1468.txt into examples\n",
      "data/train\\raw_text\\1469.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1469.txt into examples\n",
      "data/train\\raw_text\\147.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\147.txt into examples\n",
      "data/train\\raw_text\\1470.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1470.txt into examples\n",
      "data/train\\raw_text\\1471.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1471.txt into examples\n",
      "data/train\\raw_text\\1472.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1472.txt into examples\n",
      "data/train\\raw_text\\1473.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1473.txt into examples\n",
      "data/train\\raw_text\\1474.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1474.txt into examples\n",
      "data/train\\raw_text\\1475.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1475.txt into examples\n",
      "data/train\\raw_text\\1476.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1476.txt into examples\n",
      "data/train\\raw_text\\1477.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1477.txt into examples\n",
      "data/train\\raw_text\\1478.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1478.txt into examples\n",
      "data/train\\raw_text\\1479.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1479.txt into examples\n",
      "data/train\\raw_text\\148.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\148.txt into examples\n",
      "data/train\\raw_text\\1480.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1480.txt into examples\n",
      "data/train\\raw_text\\1481.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1481.txt into examples\n",
      "data/train\\raw_text\\1482.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1482.txt into examples\n",
      "data/train\\raw_text\\1483.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1483.txt into examples\n",
      "data/train\\raw_text\\1484.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1484.txt into examples\n",
      "data/train\\raw_text\\1485.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1485.txt into examples\n",
      "data/train\\raw_text\\1486.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1486.txt into examples\n",
      "data/train\\raw_text\\1487.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1487.txt into examples\n",
      "data/train\\raw_text\\1488.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1488.txt into examples\n",
      "data/train\\raw_text\\1489.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1489.txt into examples\n",
      "data/train\\raw_text\\149.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\149.txt into examples\n",
      "data/train\\raw_text\\1490.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1490.txt into examples\n",
      "data/train\\raw_text\\1491.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1491.txt into examples\n",
      "data/train\\raw_text\\1492.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1492.txt into examples\n",
      "data/train\\raw_text\\1493.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1493.txt into examples\n",
      "data/train\\raw_text\\1494.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1494.txt into examples\n",
      "data/train\\raw_text\\1495.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1495.txt into examples\n",
      "data/train\\raw_text\\1496.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1496.txt into examples\n",
      "data/train\\raw_text\\1497.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1497.txt into examples\n",
      "data/train\\raw_text\\1498.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1498.txt into examples\n",
      "data/train\\raw_text\\1499.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1499.txt into examples\n",
      "data/train\\raw_text\\15.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\15.txt into examples\n",
      "data/train\\raw_text\\150.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\150.txt into examples\n",
      "data/train\\raw_text\\1500.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1500.txt into examples\n",
      "data/train\\raw_text\\1501.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1501.txt into examples\n",
      "data/train\\raw_text\\1502.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1502.txt into examples\n",
      "data/train\\raw_text\\1503.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1503.txt into examples\n",
      "data/train\\raw_text\\1504.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1504.txt into examples\n",
      "data/train\\raw_text\\1505.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1505.txt into examples\n",
      "data/train\\raw_text\\1506.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1506.txt into examples\n",
      "data/train\\raw_text\\1507.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1507.txt into examples\n",
      "data/train\\raw_text\\1508.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1508.txt into examples\n",
      "data/train\\raw_text\\1509.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1509.txt into examples\n",
      "data/train\\raw_text\\151.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\151.txt into examples\n",
      "data/train\\raw_text\\1510.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1510.txt into examples\n",
      "data/train\\raw_text\\1511.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1511.txt into examples\n",
      "data/train\\raw_text\\1512.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1512.txt into examples\n",
      "data/train\\raw_text\\1513.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1513.txt into examples\n",
      "data/train\\raw_text\\1514.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1514.txt into examples\n",
      "data/train\\raw_text\\1515.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1515.txt into examples\n",
      "data/train\\raw_text\\1516.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1516.txt into examples\n",
      "data/train\\raw_text\\1517.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1517.txt into examples\n",
      "data/train\\raw_text\\1518.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1518.txt into examples\n",
      "data/train\\raw_text\\1519.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1519.txt into examples\n",
      "data/train\\raw_text\\152.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\152.txt into examples\n",
      "data/train\\raw_text\\1520.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1520.txt into examples\n",
      "data/train\\raw_text\\1521.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1521.txt into examples\n",
      "data/train\\raw_text\\1522.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1522.txt into examples\n",
      "data/train\\raw_text\\1523.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1523.txt into examples\n",
      "data/train\\raw_text\\1524.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1524.txt into examples\n",
      "data/train\\raw_text\\1525.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1525.txt into examples\n",
      "data/train\\raw_text\\1526.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1526.txt into examples\n",
      "data/train\\raw_text\\1527.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1527.txt into examples\n",
      "data/train\\raw_text\\1528.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1528.txt into examples\n",
      "data/train\\raw_text\\1529.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1529.txt into examples\n",
      "data/train\\raw_text\\153.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\153.txt into examples\n",
      "data/train\\raw_text\\1530.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1530.txt into examples\n",
      "data/train\\raw_text\\1531.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1531.txt into examples\n",
      "data/train\\raw_text\\1532.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1532.txt into examples\n",
      "data/train\\raw_text\\1533.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1533.txt into examples\n",
      "data/train\\raw_text\\1534.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1534.txt into examples\n",
      "data/train\\raw_text\\1535.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1535.txt into examples\n",
      "data/train\\raw_text\\1536.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1536.txt into examples\n",
      "data/train\\raw_text\\1537.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1537.txt into examples\n",
      "data/train\\raw_text\\1538.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1538.txt into examples\n",
      "data/train\\raw_text\\1539.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1539.txt into examples\n",
      "data/train\\raw_text\\154.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\154.txt into examples\n",
      "data/train\\raw_text\\1540.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1540.txt into examples\n",
      "data/train\\raw_text\\1541.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1541.txt into examples\n",
      "data/train\\raw_text\\1542.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1542.txt into examples\n",
      "data/train\\raw_text\\1543.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1543.txt into examples\n",
      "data/train\\raw_text\\1544.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1544.txt into examples\n",
      "data/train\\raw_text\\1545.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1545.txt into examples\n",
      "data/train\\raw_text\\1546.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1546.txt into examples\n",
      "data/train\\raw_text\\1547.txt successfully read and tokenized\n",
      "80\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1547.txt into examples\n",
      "data/train\\raw_text\\1548.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1548.txt into examples\n",
      "data/train\\raw_text\\1549.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1549.txt into examples\n",
      "data/train\\raw_text\\155.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\155.txt into examples\n",
      "data/train\\raw_text\\1550.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1550.txt into examples\n",
      "data/train\\raw_text\\1551.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1551.txt into examples\n",
      "data/train\\raw_text\\1552.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1552.txt into examples\n",
      "data/train\\raw_text\\1553.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1553.txt into examples\n",
      "data/train\\raw_text\\1554.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1554.txt into examples\n",
      "data/train\\raw_text\\1555.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1555.txt into examples\n",
      "data/train\\raw_text\\1556.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1556.txt into examples\n",
      "data/train\\raw_text\\1557.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1557.txt into examples\n",
      "data/train\\raw_text\\1558.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1558.txt into examples\n",
      "data/train\\raw_text\\1559.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1559.txt into examples\n",
      "data/train\\raw_text\\156.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\156.txt into examples\n",
      "data/train\\raw_text\\1560.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1560.txt into examples\n",
      "data/train\\raw_text\\1561.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1561.txt into examples\n",
      "data/train\\raw_text\\1562.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1562.txt into examples\n",
      "data/train\\raw_text\\1563.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1563.txt into examples\n",
      "data/train\\raw_text\\1564.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1564.txt into examples\n",
      "data/train\\raw_text\\1565.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1565.txt into examples\n",
      "data/train\\raw_text\\1566.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1566.txt into examples\n",
      "data/train\\raw_text\\1567.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1567.txt into examples\n",
      "data/train\\raw_text\\1568.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1568.txt into examples\n",
      "data/train\\raw_text\\1569.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1569.txt into examples\n",
      "data/train\\raw_text\\157.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\157.txt into examples\n",
      "data/train\\raw_text\\1570.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1570.txt into examples\n",
      "data/train\\raw_text\\1571.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1571.txt into examples\n",
      "data/train\\raw_text\\1572.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1572.txt into examples\n",
      "data/train\\raw_text\\1573.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1573.txt into examples\n",
      "data/train\\raw_text\\1574.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1574.txt into examples\n",
      "data/train\\raw_text\\1575.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1575.txt into examples\n",
      "data/train\\raw_text\\1576.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1576.txt into examples\n",
      "data/train\\raw_text\\1577.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1577.txt into examples\n",
      "data/train\\raw_text\\1578.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1578.txt into examples\n",
      "data/train\\raw_text\\1579.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1579.txt into examples\n",
      "data/train\\raw_text\\158.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\158.txt into examples\n",
      "data/train\\raw_text\\1580.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1580.txt into examples\n",
      "data/train\\raw_text\\1581.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1581.txt into examples\n",
      "data/train\\raw_text\\1582.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1582.txt into examples\n",
      "data/train\\raw_text\\1583.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1583.txt into examples\n",
      "data/train\\raw_text\\1584.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1584.txt into examples\n",
      "data/train\\raw_text\\1585.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1585.txt into examples\n",
      "data/train\\raw_text\\1586.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1586.txt into examples\n",
      "data/train\\raw_text\\1587.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1587.txt into examples\n",
      "data/train\\raw_text\\1588.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1588.txt into examples\n",
      "data/train\\raw_text\\1589.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1589.txt into examples\n",
      "data/train\\raw_text\\159.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\159.txt into examples\n",
      "data/train\\raw_text\\1590.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1590.txt into examples\n",
      "data/train\\raw_text\\1591.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1591.txt into examples\n",
      "data/train\\raw_text\\1592.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1592.txt into examples\n",
      "data/train\\raw_text\\1593.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1593.txt into examples\n",
      "data/train\\raw_text\\1594.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1594.txt into examples\n",
      "data/train\\raw_text\\1595.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1595.txt into examples\n",
      "data/train\\raw_text\\1596.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1596.txt into examples\n",
      "data/train\\raw_text\\1597.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1597.txt into examples\n",
      "data/train\\raw_text\\1598.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1598.txt into examples\n",
      "data/train\\raw_text\\1599.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1599.txt into examples\n",
      "data/train\\raw_text\\16.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\16.txt into examples\n",
      "data/train\\raw_text\\160.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\160.txt into examples\n",
      "data/train\\raw_text\\1600.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1600.txt into examples\n",
      "data/train\\raw_text\\1601.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1601.txt into examples\n",
      "data/train\\raw_text\\1602.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1602.txt into examples\n",
      "data/train\\raw_text\\1603.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1603.txt into examples\n",
      "data/train\\raw_text\\1604.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1604.txt into examples\n",
      "data/train\\raw_text\\1605.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1605.txt into examples\n",
      "data/train\\raw_text\\1606.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1606.txt into examples\n",
      "data/train\\raw_text\\1607.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1607.txt into examples\n",
      "data/train\\raw_text\\1608.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1608.txt into examples\n",
      "data/train\\raw_text\\1609.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1609.txt into examples\n",
      "data/train\\raw_text\\161.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\161.txt into examples\n",
      "data/train\\raw_text\\1610.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1610.txt into examples\n",
      "data/train\\raw_text\\1611.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1611.txt into examples\n",
      "data/train\\raw_text\\1612.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1612.txt into examples\n",
      "data/train\\raw_text\\1613.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1613.txt into examples\n",
      "data/train\\raw_text\\1614.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1614.txt into examples\n",
      "data/train\\raw_text\\1615.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1615.txt into examples\n",
      "data/train\\raw_text\\1616.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1616.txt into examples\n",
      "data/train\\raw_text\\1617.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1617.txt into examples\n",
      "data/train\\raw_text\\1618.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1618.txt into examples\n",
      "data/train\\raw_text\\1619.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1619.txt into examples\n",
      "data/train\\raw_text\\162.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\162.txt into examples\n",
      "data/train\\raw_text\\1620.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1620.txt into examples\n",
      "data/train\\raw_text\\1621.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1621.txt into examples\n",
      "data/train\\raw_text\\1622.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1622.txt into examples\n",
      "data/train\\raw_text\\1623.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1623.txt into examples\n",
      "data/train\\raw_text\\1624.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1624.txt into examples\n",
      "data/train\\raw_text\\1625.txt successfully read and tokenized\n",
      "79\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1625.txt into examples\n",
      "data/train\\raw_text\\1626.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1626.txt into examples\n",
      "data/train\\raw_text\\1627.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1627.txt into examples\n",
      "data/train\\raw_text\\1628.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1628.txt into examples\n",
      "data/train\\raw_text\\1629.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1629.txt into examples\n",
      "data/train\\raw_text\\163.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\163.txt into examples\n",
      "data/train\\raw_text\\1630.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1630.txt into examples\n",
      "data/train\\raw_text\\1631.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1631.txt into examples\n",
      "data/train\\raw_text\\1632.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1632.txt into examples\n",
      "data/train\\raw_text\\1633.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1633.txt into examples\n",
      "data/train\\raw_text\\1634.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1634.txt into examples\n",
      "data/train\\raw_text\\1635.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1635.txt into examples\n",
      "data/train\\raw_text\\1636.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1636.txt into examples\n",
      "data/train\\raw_text\\1637.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1637.txt into examples\n",
      "data/train\\raw_text\\1638.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1638.txt into examples\n",
      "data/train\\raw_text\\1639.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1639.txt into examples\n",
      "data/train\\raw_text\\164.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\164.txt into examples\n",
      "data/train\\raw_text\\1640.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1640.txt into examples\n",
      "data/train\\raw_text\\1641.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1641.txt into examples\n",
      "data/train\\raw_text\\1642.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1642.txt into examples\n",
      "data/train\\raw_text\\1643.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1643.txt into examples\n",
      "data/train\\raw_text\\1644.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1644.txt into examples\n",
      "data/train\\raw_text\\1645.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1645.txt into examples\n",
      "data/train\\raw_text\\1646.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1646.txt into examples\n",
      "data/train\\raw_text\\1647.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1647.txt into examples\n",
      "data/train\\raw_text\\1648.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1648.txt into examples\n",
      "data/train\\raw_text\\1649.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1649.txt into examples\n",
      "data/train\\raw_text\\165.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\165.txt into examples\n",
      "data/train\\raw_text\\1650.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1650.txt into examples\n",
      "data/train\\raw_text\\1651.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1651.txt into examples\n",
      "data/train\\raw_text\\1652.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1652.txt into examples\n",
      "data/train\\raw_text\\1653.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1653.txt into examples\n",
      "data/train\\raw_text\\1654.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1654.txt into examples\n",
      "data/train\\raw_text\\1655.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1655.txt into examples\n",
      "data/train\\raw_text\\1656.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1656.txt into examples\n",
      "data/train\\raw_text\\1657.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1657.txt into examples\n",
      "data/train\\raw_text\\1658.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1658.txt into examples\n",
      "data/train\\raw_text\\1659.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1659.txt into examples\n",
      "data/train\\raw_text\\166.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\166.txt into examples\n",
      "data/train\\raw_text\\1660.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1660.txt into examples\n",
      "data/train\\raw_text\\1661.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1661.txt into examples\n",
      "data/train\\raw_text\\1662.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1662.txt into examples\n",
      "data/train\\raw_text\\1663.txt successfully read and tokenized\n",
      "76\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1663.txt into examples\n",
      "data/train\\raw_text\\1664.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1664.txt into examples\n",
      "data/train\\raw_text\\1665.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1665.txt into examples\n",
      "data/train\\raw_text\\1666.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1666.txt into examples\n",
      "data/train\\raw_text\\1667.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1667.txt into examples\n",
      "data/train\\raw_text\\1668.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1668.txt into examples\n",
      "data/train\\raw_text\\1669.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1669.txt into examples\n",
      "data/train\\raw_text\\167.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\167.txt into examples\n",
      "data/train\\raw_text\\1670.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1670.txt into examples\n",
      "data/train\\raw_text\\1671.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1671.txt into examples\n",
      "data/train\\raw_text\\1672.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1672.txt into examples\n",
      "data/train\\raw_text\\1673.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1673.txt into examples\n",
      "data/train\\raw_text\\1674.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1674.txt into examples\n",
      "data/train\\raw_text\\1675.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1675.txt into examples\n",
      "data/train\\raw_text\\1676.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1676.txt into examples\n",
      "data/train\\raw_text\\1677.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1677.txt into examples\n",
      "data/train\\raw_text\\1678.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1678.txt into examples\n",
      "data/train\\raw_text\\1679.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1679.txt into examples\n",
      "data/train\\raw_text\\168.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\168.txt into examples\n",
      "data/train\\raw_text\\1680.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1680.txt into examples\n",
      "data/train\\raw_text\\1681.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1681.txt into examples\n",
      "data/train\\raw_text\\1682.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1682.txt into examples\n",
      "data/train\\raw_text\\1683.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1683.txt into examples\n",
      "data/train\\raw_text\\1684.txt successfully read and tokenized\n",
      "81\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1684.txt into examples\n",
      "data/train\\raw_text\\1685.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1685.txt into examples\n",
      "data/train\\raw_text\\1686.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1686.txt into examples\n",
      "data/train\\raw_text\\1687.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1687.txt into examples\n",
      "data/train\\raw_text\\1688.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1688.txt into examples\n",
      "data/train\\raw_text\\1689.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1689.txt into examples\n",
      "data/train\\raw_text\\169.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\169.txt into examples\n",
      "data/train\\raw_text\\1690.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1690.txt into examples\n",
      "data/train\\raw_text\\1691.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1691.txt into examples\n",
      "data/train\\raw_text\\1692.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1692.txt into examples\n",
      "data/train\\raw_text\\1693.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1693.txt into examples\n",
      "data/train\\raw_text\\1694.txt successfully read and tokenized\n",
      "84\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1694.txt into examples\n",
      "data/train\\raw_text\\1695.txt successfully read and tokenized\n",
      "79\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1695.txt into examples\n",
      "data/train\\raw_text\\1696.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1696.txt into examples\n",
      "data/train\\raw_text\\1697.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1697.txt into examples\n",
      "data/train\\raw_text\\1698.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1698.txt into examples\n",
      "data/train\\raw_text\\1699.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1699.txt into examples\n",
      "data/train\\raw_text\\17.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\17.txt into examples\n",
      "data/train\\raw_text\\170.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\170.txt into examples\n",
      "data/train\\raw_text\\1700.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1700.txt into examples\n",
      "data/train\\raw_text\\1701.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1701.txt into examples\n",
      "data/train\\raw_text\\1702.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1702.txt into examples\n",
      "data/train\\raw_text\\1703.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1703.txt into examples\n",
      "data/train\\raw_text\\1704.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1704.txt into examples\n",
      "data/train\\raw_text\\1705.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1705.txt into examples\n",
      "data/train\\raw_text\\1706.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1706.txt into examples\n",
      "data/train\\raw_text\\1707.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1707.txt into examples\n",
      "data/train\\raw_text\\1708.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1708.txt into examples\n",
      "data/train\\raw_text\\1709.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1709.txt into examples\n",
      "data/train\\raw_text\\171.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\171.txt into examples\n",
      "data/train\\raw_text\\1710.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1710.txt into examples\n",
      "data/train\\raw_text\\1711.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1711.txt into examples\n",
      "data/train\\raw_text\\1712.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1712.txt into examples\n",
      "data/train\\raw_text\\1713.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1713.txt into examples\n",
      "data/train\\raw_text\\1714.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1714.txt into examples\n",
      "data/train\\raw_text\\1715.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1715.txt into examples\n",
      "data/train\\raw_text\\1716.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1716.txt into examples\n",
      "data/train\\raw_text\\1717.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1717.txt into examples\n",
      "data/train\\raw_text\\1718.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1718.txt into examples\n",
      "data/train\\raw_text\\1719.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1719.txt into examples\n",
      "data/train\\raw_text\\172.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\172.txt into examples\n",
      "data/train\\raw_text\\1720.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1720.txt into examples\n",
      "data/train\\raw_text\\1721.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1721.txt into examples\n",
      "data/train\\raw_text\\1722.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1722.txt into examples\n",
      "data/train\\raw_text\\1723.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1723.txt into examples\n",
      "data/train\\raw_text\\1724.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1724.txt into examples\n",
      "data/train\\raw_text\\1725.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1725.txt into examples\n",
      "data/train\\raw_text\\1726.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1726.txt into examples\n",
      "data/train\\raw_text\\1727.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1727.txt into examples\n",
      "data/train\\raw_text\\1728.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1728.txt into examples\n",
      "data/train\\raw_text\\1729.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1729.txt into examples\n",
      "data/train\\raw_text\\173.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\173.txt into examples\n",
      "data/train\\raw_text\\1730.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1730.txt into examples\n",
      "data/train\\raw_text\\1731.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1731.txt into examples\n",
      "data/train\\raw_text\\1732.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1732.txt into examples\n",
      "data/train\\raw_text\\1733.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1733.txt into examples\n",
      "data/train\\raw_text\\1734.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1734.txt into examples\n",
      "data/train\\raw_text\\1735.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1735.txt into examples\n",
      "data/train\\raw_text\\1736.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1736.txt into examples\n",
      "data/train\\raw_text\\1737.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1737.txt into examples\n",
      "data/train\\raw_text\\1738.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1738.txt into examples\n",
      "data/train\\raw_text\\1739.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1739.txt into examples\n",
      "data/train\\raw_text\\174.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\174.txt into examples\n",
      "data/train\\raw_text\\1740.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1740.txt into examples\n",
      "data/train\\raw_text\\1741.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1741.txt into examples\n",
      "data/train\\raw_text\\1742.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1742.txt into examples\n",
      "data/train\\raw_text\\1743.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1743.txt into examples\n",
      "data/train\\raw_text\\1744.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1744.txt into examples\n",
      "data/train\\raw_text\\1745.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1745.txt into examples\n",
      "data/train\\raw_text\\1746.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1746.txt into examples\n",
      "data/train\\raw_text\\1747.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1747.txt into examples\n",
      "data/train\\raw_text\\1748.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1748.txt into examples\n",
      "data/train\\raw_text\\1749.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1749.txt into examples\n",
      "data/train\\raw_text\\175.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\175.txt into examples\n",
      "data/train\\raw_text\\1750.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1750.txt into examples\n",
      "data/train\\raw_text\\1751.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1751.txt into examples\n",
      "data/train\\raw_text\\1752.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1752.txt into examples\n",
      "data/train\\raw_text\\1753.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1753.txt into examples\n",
      "data/train\\raw_text\\1754.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1754.txt into examples\n",
      "data/train\\raw_text\\1755.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1755.txt into examples\n",
      "data/train\\raw_text\\1756.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1756.txt into examples\n",
      "data/train\\raw_text\\1757.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1757.txt into examples\n",
      "data/train\\raw_text\\1758.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1758.txt into examples\n",
      "data/train\\raw_text\\1759.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1759.txt into examples\n",
      "data/train\\raw_text\\176.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\176.txt into examples\n",
      "data/train\\raw_text\\1760.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1760.txt into examples\n",
      "data/train\\raw_text\\1761.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1761.txt into examples\n",
      "data/train\\raw_text\\1762.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1762.txt into examples\n",
      "data/train\\raw_text\\1763.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1763.txt into examples\n",
      "data/train\\raw_text\\1764.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1764.txt into examples\n",
      "data/train\\raw_text\\1765.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1765.txt into examples\n",
      "data/train\\raw_text\\1766.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1766.txt into examples\n",
      "data/train\\raw_text\\1767.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1767.txt into examples\n",
      "data/train\\raw_text\\1768.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1768.txt into examples\n",
      "data/train\\raw_text\\1769.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1769.txt into examples\n",
      "data/train\\raw_text\\177.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\177.txt into examples\n",
      "data/train\\raw_text\\1770.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1770.txt into examples\n",
      "data/train\\raw_text\\1771.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1771.txt into examples\n",
      "data/train\\raw_text\\1772.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1772.txt into examples\n",
      "data/train\\raw_text\\1773.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1773.txt into examples\n",
      "data/train\\raw_text\\1774.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1774.txt into examples\n",
      "data/train\\raw_text\\1775.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1775.txt into examples\n",
      "data/train\\raw_text\\1776.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1776.txt into examples\n",
      "data/train\\raw_text\\1777.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1777.txt into examples\n",
      "data/train\\raw_text\\1778.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1778.txt into examples\n",
      "data/train\\raw_text\\1779.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1779.txt into examples\n",
      "data/train\\raw_text\\178.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\178.txt into examples\n",
      "data/train\\raw_text\\1780.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1780.txt into examples\n",
      "data/train\\raw_text\\1781.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1781.txt into examples\n",
      "data/train\\raw_text\\1782.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1782.txt into examples\n",
      "data/train\\raw_text\\1783.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1783.txt into examples\n",
      "data/train\\raw_text\\1784.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1784.txt into examples\n",
      "data/train\\raw_text\\1785.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1785.txt into examples\n",
      "data/train\\raw_text\\1786.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1786.txt into examples\n",
      "data/train\\raw_text\\1787.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1787.txt into examples\n",
      "data/train\\raw_text\\1788.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1788.txt into examples\n",
      "data/train\\raw_text\\1789.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1789.txt into examples\n",
      "data/train\\raw_text\\179.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\179.txt into examples\n",
      "data/train\\raw_text\\1790.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1790.txt into examples\n",
      "data/train\\raw_text\\1791.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1791.txt into examples\n",
      "data/train\\raw_text\\1792.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1792.txt into examples\n",
      "data/train\\raw_text\\1793.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1793.txt into examples\n",
      "data/train\\raw_text\\1794.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1794.txt into examples\n",
      "data/train\\raw_text\\1795.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1795.txt into examples\n",
      "data/train\\raw_text\\1796.txt successfully read and tokenized\n",
      "39\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1796.txt into examples\n",
      "data/train\\raw_text\\1797.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1797.txt into examples\n",
      "data/train\\raw_text\\1798.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1798.txt into examples\n",
      "data/train\\raw_text\\1799.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1799.txt into examples\n",
      "data/train\\raw_text\\18.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\18.txt into examples\n",
      "data/train\\raw_text\\180.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\180.txt into examples\n",
      "data/train\\raw_text\\1800.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1800.txt into examples\n",
      "data/train\\raw_text\\1801.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1801.txt into examples\n",
      "data/train\\raw_text\\1802.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1802.txt into examples\n",
      "data/train\\raw_text\\1803.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1803.txt into examples\n",
      "data/train\\raw_text\\1804.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1804.txt into examples\n",
      "data/train\\raw_text\\1805.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1805.txt into examples\n",
      "data/train\\raw_text\\1806.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1806.txt into examples\n",
      "data/train\\raw_text\\1807.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1807.txt into examples\n",
      "data/train\\raw_text\\1808.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1808.txt into examples\n",
      "data/train\\raw_text\\1809.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1809.txt into examples\n",
      "data/train\\raw_text\\181.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\181.txt into examples\n",
      "data/train\\raw_text\\1810.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1810.txt into examples\n",
      "data/train\\raw_text\\1811.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1811.txt into examples\n",
      "data/train\\raw_text\\1812.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1812.txt into examples\n",
      "data/train\\raw_text\\1813.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1813.txt into examples\n",
      "data/train\\raw_text\\1814.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1814.txt into examples\n",
      "data/train\\raw_text\\1815.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1815.txt into examples\n",
      "data/train\\raw_text\\1816.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1816.txt into examples\n",
      "data/train\\raw_text\\1817.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1817.txt into examples\n",
      "data/train\\raw_text\\1818.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1818.txt into examples\n",
      "data/train\\raw_text\\1819.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1819.txt into examples\n",
      "data/train\\raw_text\\182.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\182.txt into examples\n",
      "data/train\\raw_text\\1820.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1820.txt into examples\n",
      "data/train\\raw_text\\1821.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1821.txt into examples\n",
      "data/train\\raw_text\\1822.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1822.txt into examples\n",
      "data/train\\raw_text\\1823.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1823.txt into examples\n",
      "data/train\\raw_text\\1824.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1824.txt into examples\n",
      "data/train\\raw_text\\1825.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1825.txt into examples\n",
      "data/train\\raw_text\\1826.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1826.txt into examples\n",
      "data/train\\raw_text\\1827.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1827.txt into examples\n",
      "data/train\\raw_text\\1828.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1828.txt into examples\n",
      "data/train\\raw_text\\1829.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1829.txt into examples\n",
      "data/train\\raw_text\\183.txt successfully read and tokenized\n",
      "78\n",
      "Failed at splitting tokens from file data/train\\raw_text\\183.txt into examples\n",
      "data/train\\raw_text\\1830.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1830.txt into examples\n",
      "data/train\\raw_text\\1831.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1831.txt into examples\n",
      "data/train\\raw_text\\1832.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1832.txt into examples\n",
      "data/train\\raw_text\\1833.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1833.txt into examples\n",
      "data/train\\raw_text\\1834.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1834.txt into examples\n",
      "data/train\\raw_text\\1835.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1835.txt into examples\n",
      "data/train\\raw_text\\1836.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1836.txt into examples\n",
      "data/train\\raw_text\\1837.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1837.txt into examples\n",
      "data/train\\raw_text\\1838.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1838.txt into examples\n",
      "data/train\\raw_text\\1839.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1839.txt into examples\n",
      "data/train\\raw_text\\184.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\184.txt into examples\n",
      "data/train\\raw_text\\1840.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1840.txt into examples\n",
      "data/train\\raw_text\\1841.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1841.txt into examples\n",
      "data/train\\raw_text\\1842.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1842.txt into examples\n",
      "data/train\\raw_text\\1843.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1843.txt into examples\n",
      "data/train\\raw_text\\1844.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1844.txt into examples\n",
      "data/train\\raw_text\\1845.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1845.txt into examples\n",
      "data/train\\raw_text\\1846.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1846.txt into examples\n",
      "data/train\\raw_text\\1847.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1847.txt into examples\n",
      "data/train\\raw_text\\1848.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1848.txt into examples\n",
      "data/train\\raw_text\\1849.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1849.txt into examples\n",
      "data/train\\raw_text\\185.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\185.txt into examples\n",
      "data/train\\raw_text\\1850.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1850.txt into examples\n",
      "data/train\\raw_text\\1851.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1851.txt into examples\n",
      "data/train\\raw_text\\1852.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1852.txt into examples\n",
      "data/train\\raw_text\\1853.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1853.txt into examples\n",
      "data/train\\raw_text\\1854.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1854.txt into examples\n",
      "data/train\\raw_text\\1855.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1855.txt into examples\n",
      "data/train\\raw_text\\1856.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1856.txt into examples\n",
      "data/train\\raw_text\\1857.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1857.txt into examples\n",
      "data/train\\raw_text\\1858.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1858.txt into examples\n",
      "data/train\\raw_text\\1859.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1859.txt into examples\n",
      "data/train\\raw_text\\186.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\186.txt into examples\n",
      "data/train\\raw_text\\1860.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1860.txt into examples\n",
      "data/train\\raw_text\\1861.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1861.txt into examples\n",
      "data/train\\raw_text\\1862.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1862.txt into examples\n",
      "data/train\\raw_text\\1863.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1863.txt into examples\n",
      "data/train\\raw_text\\1864.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1864.txt into examples\n",
      "data/train\\raw_text\\1865.txt successfully read and tokenized\n",
      "36\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1865.txt into examples\n",
      "data/train\\raw_text\\1866.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1866.txt into examples\n",
      "data/train\\raw_text\\1867.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1867.txt into examples\n",
      "data/train\\raw_text\\1868.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1868.txt into examples\n",
      "data/train\\raw_text\\1869.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1869.txt into examples\n",
      "data/train\\raw_text\\187.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\187.txt into examples\n",
      "data/train\\raw_text\\1870.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1870.txt into examples\n",
      "data/train\\raw_text\\1871.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1871.txt into examples\n",
      "data/train\\raw_text\\1872.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1872.txt into examples\n",
      "data/train\\raw_text\\1873.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1873.txt into examples\n",
      "data/train\\raw_text\\1874.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1874.txt into examples\n",
      "data/train\\raw_text\\1875.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1875.txt into examples\n",
      "data/train\\raw_text\\1876.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1876.txt into examples\n",
      "data/train\\raw_text\\1877.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1877.txt into examples\n",
      "data/train\\raw_text\\1878.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1878.txt into examples\n",
      "data/train\\raw_text\\1879.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1879.txt into examples\n",
      "data/train\\raw_text\\188.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\188.txt into examples\n",
      "data/train\\raw_text\\1880.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1880.txt into examples\n",
      "data/train\\raw_text\\1881.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1881.txt into examples\n",
      "data/train\\raw_text\\1882.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1882.txt into examples\n",
      "data/train\\raw_text\\1883.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1883.txt into examples\n",
      "data/train\\raw_text\\1884.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1884.txt into examples\n",
      "data/train\\raw_text\\1885.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1885.txt into examples\n",
      "data/train\\raw_text\\1886.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1886.txt into examples\n",
      "data/train\\raw_text\\1887.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1887.txt into examples\n",
      "data/train\\raw_text\\1888.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1888.txt into examples\n",
      "data/train\\raw_text\\1889.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1889.txt into examples\n",
      "data/train\\raw_text\\189.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\189.txt into examples\n",
      "data/train\\raw_text\\1890.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1890.txt into examples\n",
      "data/train\\raw_text\\1891.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1891.txt into examples\n",
      "data/train\\raw_text\\1892.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1892.txt into examples\n",
      "data/train\\raw_text\\1893.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1893.txt into examples\n",
      "data/train\\raw_text\\1894.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1894.txt into examples\n",
      "data/train\\raw_text\\1895.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1895.txt into examples\n",
      "data/train\\raw_text\\1896.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1896.txt into examples\n",
      "data/train\\raw_text\\1897.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1897.txt into examples\n",
      "data/train\\raw_text\\1898.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1898.txt into examples\n",
      "data/train\\raw_text\\1899.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1899.txt into examples\n",
      "data/train\\raw_text\\19.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\19.txt into examples\n",
      "data/train\\raw_text\\190.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\190.txt into examples\n",
      "data/train\\raw_text\\1900.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1900.txt into examples\n",
      "data/train\\raw_text\\1901.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1901.txt into examples\n",
      "data/train\\raw_text\\1902.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1902.txt into examples\n",
      "data/train\\raw_text\\1903.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1903.txt into examples\n",
      "data/train\\raw_text\\1904.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1904.txt into examples\n",
      "data/train\\raw_text\\1905.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1905.txt into examples\n",
      "data/train\\raw_text\\1906.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1906.txt into examples\n",
      "data/train\\raw_text\\1907.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1907.txt into examples\n",
      "data/train\\raw_text\\1908.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1908.txt into examples\n",
      "data/train\\raw_text\\1909.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1909.txt into examples\n",
      "data/train\\raw_text\\191.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\191.txt into examples\n",
      "data/train\\raw_text\\1910.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1910.txt into examples\n",
      "data/train\\raw_text\\1911.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1911.txt into examples\n",
      "data/train\\raw_text\\1912.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1912.txt into examples\n",
      "data/train\\raw_text\\1913.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1913.txt into examples\n",
      "data/train\\raw_text\\1914.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1914.txt into examples\n",
      "data/train\\raw_text\\1915.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1915.txt into examples\n",
      "data/train\\raw_text\\1916.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1916.txt into examples\n",
      "data/train\\raw_text\\1917.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1917.txt into examples\n",
      "data/train\\raw_text\\1918.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1918.txt into examples\n",
      "data/train\\raw_text\\1919.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1919.txt into examples\n",
      "data/train\\raw_text\\192.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\192.txt into examples\n",
      "data/train\\raw_text\\1920.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1920.txt into examples\n",
      "data/train\\raw_text\\1921.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1921.txt into examples\n",
      "data/train\\raw_text\\1922.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1922.txt into examples\n",
      "data/train\\raw_text\\1923.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1923.txt into examples\n",
      "data/train\\raw_text\\1924.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1924.txt into examples\n",
      "data/train\\raw_text\\1925.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1925.txt into examples\n",
      "data/train\\raw_text\\1926.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1926.txt into examples\n",
      "data/train\\raw_text\\1927.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1927.txt into examples\n",
      "data/train\\raw_text\\1928.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1928.txt into examples\n",
      "data/train\\raw_text\\1929.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1929.txt into examples\n",
      "data/train\\raw_text\\193.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\193.txt into examples\n",
      "data/train\\raw_text\\1930.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1930.txt into examples\n",
      "data/train\\raw_text\\1931.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1931.txt into examples\n",
      "data/train\\raw_text\\1932.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1932.txt into examples\n",
      "data/train\\raw_text\\1933.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1933.txt into examples\n",
      "data/train\\raw_text\\1934.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1934.txt into examples\n",
      "data/train\\raw_text\\1935.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1935.txt into examples\n",
      "data/train\\raw_text\\1936.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1936.txt into examples\n",
      "data/train\\raw_text\\1937.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1937.txt into examples\n",
      "data/train\\raw_text\\1938.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1938.txt into examples\n",
      "data/train\\raw_text\\1939.txt successfully read and tokenized\n",
      "39\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1939.txt into examples\n",
      "data/train\\raw_text\\194.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\194.txt into examples\n",
      "data/train\\raw_text\\1940.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1940.txt into examples\n",
      "data/train\\raw_text\\1941.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1941.txt into examples\n",
      "data/train\\raw_text\\1942.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1942.txt into examples\n",
      "data/train\\raw_text\\1943.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1943.txt into examples\n",
      "data/train\\raw_text\\1944.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1944.txt into examples\n",
      "data/train\\raw_text\\1945.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1945.txt into examples\n",
      "data/train\\raw_text\\1946.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1946.txt into examples\n",
      "data/train\\raw_text\\1947.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1947.txt into examples\n",
      "data/train\\raw_text\\1948.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1948.txt into examples\n",
      "data/train\\raw_text\\1949.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1949.txt into examples\n",
      "data/train\\raw_text\\195.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\195.txt into examples\n",
      "data/train\\raw_text\\1950.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1950.txt into examples\n",
      "data/train\\raw_text\\1951.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1951.txt into examples\n",
      "data/train\\raw_text\\1952.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1952.txt into examples\n",
      "data/train\\raw_text\\1953.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1953.txt into examples\n",
      "data/train\\raw_text\\1954.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1954.txt into examples\n",
      "data/train\\raw_text\\1955.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1955.txt into examples\n",
      "data/train\\raw_text\\1956.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1956.txt into examples\n",
      "data/train\\raw_text\\1957.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1957.txt into examples\n",
      "data/train\\raw_text\\1958.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1958.txt into examples\n",
      "data/train\\raw_text\\1959.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1959.txt into examples\n",
      "data/train\\raw_text\\196.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\196.txt into examples\n",
      "data/train\\raw_text\\1960.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1960.txt into examples\n",
      "data/train\\raw_text\\1961.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1961.txt into examples\n",
      "data/train\\raw_text\\1962.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1962.txt into examples\n",
      "data/train\\raw_text\\1963.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1963.txt into examples\n",
      "data/train\\raw_text\\1964.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1964.txt into examples\n",
      "data/train\\raw_text\\1965.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1965.txt into examples\n",
      "data/train\\raw_text\\1966.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1966.txt into examples\n",
      "data/train\\raw_text\\1967.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1967.txt into examples\n",
      "data/train\\raw_text\\1968.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1968.txt into examples\n",
      "data/train\\raw_text\\1969.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1969.txt into examples\n",
      "data/train\\raw_text\\197.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\197.txt into examples\n",
      "data/train\\raw_text\\1970.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1970.txt into examples\n",
      "data/train\\raw_text\\1971.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1971.txt into examples\n",
      "data/train\\raw_text\\1972.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1972.txt into examples\n",
      "data/train\\raw_text\\1973.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1973.txt into examples\n",
      "data/train\\raw_text\\1974.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1974.txt into examples\n",
      "data/train\\raw_text\\1975.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1975.txt into examples\n",
      "data/train\\raw_text\\1976.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1976.txt into examples\n",
      "data/train\\raw_text\\1977.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1977.txt into examples\n",
      "data/train\\raw_text\\1978.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1978.txt into examples\n",
      "data/train\\raw_text\\1979.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1979.txt into examples\n",
      "data/train\\raw_text\\198.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\198.txt into examples\n",
      "data/train\\raw_text\\1980.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1980.txt into examples\n",
      "data/train\\raw_text\\1981.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1981.txt into examples\n",
      "data/train\\raw_text\\1982.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1982.txt into examples\n",
      "data/train\\raw_text\\1983.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1983.txt into examples\n",
      "data/train\\raw_text\\1984.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1984.txt into examples\n",
      "data/train\\raw_text\\1985.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1985.txt into examples\n",
      "data/train\\raw_text\\1986.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1986.txt into examples\n",
      "data/train\\raw_text\\1987.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1987.txt into examples\n",
      "data/train\\raw_text\\1988.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1988.txt into examples\n",
      "data/train\\raw_text\\1989.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1989.txt into examples\n",
      "data/train\\raw_text\\199.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\199.txt into examples\n",
      "data/train\\raw_text\\1990.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1990.txt into examples\n",
      "data/train\\raw_text\\1991.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1991.txt into examples\n",
      "data/train\\raw_text\\1992.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1992.txt into examples\n",
      "data/train\\raw_text\\1993.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1993.txt into examples\n",
      "data/train\\raw_text\\1994.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1994.txt into examples\n",
      "data/train\\raw_text\\1995.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1995.txt into examples\n",
      "data/train\\raw_text\\1996.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1996.txt into examples\n",
      "data/train\\raw_text\\1997.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1997.txt into examples\n",
      "data/train\\raw_text\\1998.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1998.txt into examples\n",
      "data/train\\raw_text\\1999.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\1999.txt into examples\n",
      "data/train\\raw_text\\2.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\2.txt into examples\n",
      "data/train\\raw_text\\20.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\20.txt into examples\n",
      "data/train\\raw_text\\200.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\200.txt into examples\n",
      "data/train\\raw_text\\2000.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\2000.txt into examples\n",
      "data/train\\raw_text\\201.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\201.txt into examples\n",
      "data/train\\raw_text\\202.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\202.txt into examples\n",
      "data/train\\raw_text\\203.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\203.txt into examples\n",
      "data/train\\raw_text\\204.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\204.txt into examples\n",
      "data/train\\raw_text\\205.txt successfully read and tokenized\n",
      "79\n",
      "Failed at splitting tokens from file data/train\\raw_text\\205.txt into examples\n",
      "data/train\\raw_text\\206.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\206.txt into examples\n",
      "data/train\\raw_text\\207.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\207.txt into examples\n",
      "data/train\\raw_text\\208.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\208.txt into examples\n",
      "data/train\\raw_text\\209.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\209.txt into examples\n",
      "data/train\\raw_text\\21.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\21.txt into examples\n",
      "data/train\\raw_text\\210.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\210.txt into examples\n",
      "data/train\\raw_text\\211.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\211.txt into examples\n",
      "data/train\\raw_text\\212.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\212.txt into examples\n",
      "data/train\\raw_text\\213.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\213.txt into examples\n",
      "data/train\\raw_text\\214.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\214.txt into examples\n",
      "data/train\\raw_text\\215.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\215.txt into examples\n",
      "data/train\\raw_text\\216.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\216.txt into examples\n",
      "data/train\\raw_text\\217.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\217.txt into examples\n",
      "data/train\\raw_text\\218.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\218.txt into examples\n",
      "data/train\\raw_text\\219.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\219.txt into examples\n",
      "data/train\\raw_text\\22.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\22.txt into examples\n",
      "data/train\\raw_text\\220.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\220.txt into examples\n",
      "data/train\\raw_text\\221.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\221.txt into examples\n",
      "data/train\\raw_text\\222.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\222.txt into examples\n",
      "data/train\\raw_text\\223.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\223.txt into examples\n",
      "data/train\\raw_text\\224.txt successfully read and tokenized\n",
      "90\n",
      "Failed at splitting tokens from file data/train\\raw_text\\224.txt into examples\n",
      "data/train\\raw_text\\225.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\225.txt into examples\n",
      "data/train\\raw_text\\226.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\226.txt into examples\n",
      "data/train\\raw_text\\227.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\227.txt into examples\n",
      "data/train\\raw_text\\228.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\228.txt into examples\n",
      "data/train\\raw_text\\229.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\229.txt into examples\n",
      "data/train\\raw_text\\23.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\23.txt into examples\n",
      "data/train\\raw_text\\230.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\230.txt into examples\n",
      "data/train\\raw_text\\231.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\231.txt into examples\n",
      "data/train\\raw_text\\232.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\232.txt into examples\n",
      "data/train\\raw_text\\233.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\233.txt into examples\n",
      "data/train\\raw_text\\234.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\234.txt into examples\n",
      "data/train\\raw_text\\235.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\235.txt into examples\n",
      "data/train\\raw_text\\236.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\236.txt into examples\n",
      "data/train\\raw_text\\237.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\237.txt into examples\n",
      "data/train\\raw_text\\238.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\238.txt into examples\n",
      "data/train\\raw_text\\239.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\239.txt into examples\n",
      "data/train\\raw_text\\24.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\24.txt into examples\n",
      "data/train\\raw_text\\240.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\240.txt into examples\n",
      "data/train\\raw_text\\241.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\241.txt into examples\n",
      "data/train\\raw_text\\242.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\242.txt into examples\n",
      "data/train\\raw_text\\243.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\243.txt into examples\n",
      "data/train\\raw_text\\244.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\244.txt into examples\n",
      "data/train\\raw_text\\245.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\245.txt into examples\n",
      "data/train\\raw_text\\246.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\246.txt into examples\n",
      "data/train\\raw_text\\247.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\247.txt into examples\n",
      "data/train\\raw_text\\248.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\248.txt into examples\n",
      "data/train\\raw_text\\249.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\249.txt into examples\n",
      "data/train\\raw_text\\25.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\25.txt into examples\n",
      "data/train\\raw_text\\250.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\250.txt into examples\n",
      "data/train\\raw_text\\251.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\251.txt into examples\n",
      "data/train\\raw_text\\252.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\252.txt into examples\n",
      "data/train\\raw_text\\253.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\253.txt into examples\n",
      "data/train\\raw_text\\254.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\254.txt into examples\n",
      "data/train\\raw_text\\255.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\255.txt into examples\n",
      "data/train\\raw_text\\256.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\256.txt into examples\n",
      "data/train\\raw_text\\257.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\257.txt into examples\n",
      "data/train\\raw_text\\258.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\258.txt into examples\n",
      "data/train\\raw_text\\259.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\259.txt into examples\n",
      "data/train\\raw_text\\26.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\26.txt into examples\n",
      "data/train\\raw_text\\260.txt successfully read and tokenized\n",
      "76\n",
      "Failed at splitting tokens from file data/train\\raw_text\\260.txt into examples\n",
      "data/train\\raw_text\\261.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\261.txt into examples\n",
      "data/train\\raw_text\\262.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\262.txt into examples\n",
      "data/train\\raw_text\\263.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\263.txt into examples\n",
      "data/train\\raw_text\\264.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\264.txt into examples\n",
      "data/train\\raw_text\\265.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\265.txt into examples\n",
      "data/train\\raw_text\\266.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\266.txt into examples\n",
      "data/train\\raw_text\\267.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\267.txt into examples\n",
      "data/train\\raw_text\\268.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\268.txt into examples\n",
      "data/train\\raw_text\\269.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\269.txt into examples\n",
      "data/train\\raw_text\\27.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\27.txt into examples\n",
      "data/train\\raw_text\\270.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\270.txt into examples\n",
      "data/train\\raw_text\\271.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\271.txt into examples\n",
      "data/train\\raw_text\\272.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\272.txt into examples\n",
      "data/train\\raw_text\\273.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\273.txt into examples\n",
      "data/train\\raw_text\\274.txt successfully read and tokenized\n",
      "39\n",
      "Failed at splitting tokens from file data/train\\raw_text\\274.txt into examples\n",
      "data/train\\raw_text\\275.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\275.txt into examples\n",
      "data/train\\raw_text\\276.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\276.txt into examples\n",
      "data/train\\raw_text\\277.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\277.txt into examples\n",
      "data/train\\raw_text\\278.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\278.txt into examples\n",
      "data/train\\raw_text\\279.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\279.txt into examples\n",
      "data/train\\raw_text\\28.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\28.txt into examples\n",
      "data/train\\raw_text\\280.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\280.txt into examples\n",
      "data/train\\raw_text\\281.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\281.txt into examples\n",
      "data/train\\raw_text\\282.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\282.txt into examples\n",
      "data/train\\raw_text\\283.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\283.txt into examples\n",
      "data/train\\raw_text\\284.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\284.txt into examples\n",
      "data/train\\raw_text\\285.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\285.txt into examples\n",
      "data/train\\raw_text\\286.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\286.txt into examples\n",
      "data/train\\raw_text\\287.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\287.txt into examples\n",
      "data/train\\raw_text\\288.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\288.txt into examples\n",
      "data/train\\raw_text\\289.txt successfully read and tokenized\n",
      "34\n",
      "Failed at splitting tokens from file data/train\\raw_text\\289.txt into examples\n",
      "data/train\\raw_text\\29.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\29.txt into examples\n",
      "data/train\\raw_text\\290.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\290.txt into examples\n",
      "data/train\\raw_text\\291.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\291.txt into examples\n",
      "data/train\\raw_text\\292.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\292.txt into examples\n",
      "data/train\\raw_text\\293.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\293.txt into examples\n",
      "data/train\\raw_text\\294.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\294.txt into examples\n",
      "data/train\\raw_text\\295.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\295.txt into examples\n",
      "data/train\\raw_text\\296.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\296.txt into examples\n",
      "data/train\\raw_text\\297.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\297.txt into examples\n",
      "data/train\\raw_text\\298.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\298.txt into examples\n",
      "data/train\\raw_text\\299.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\299.txt into examples\n",
      "data/train\\raw_text\\3.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\3.txt into examples\n",
      "data/train\\raw_text\\30.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\30.txt into examples\n",
      "data/train\\raw_text\\300.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\300.txt into examples\n",
      "data/train\\raw_text\\301.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\301.txt into examples\n",
      "data/train\\raw_text\\302.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\302.txt into examples\n",
      "data/train\\raw_text\\303.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\303.txt into examples\n",
      "data/train\\raw_text\\304.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\304.txt into examples\n",
      "data/train\\raw_text\\305.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\305.txt into examples\n",
      "data/train\\raw_text\\306.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\306.txt into examples\n",
      "data/train\\raw_text\\307.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\307.txt into examples\n",
      "data/train\\raw_text\\308.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\308.txt into examples\n",
      "data/train\\raw_text\\309.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\309.txt into examples\n",
      "data/train\\raw_text\\31.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\31.txt into examples\n",
      "data/train\\raw_text\\310.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\310.txt into examples\n",
      "data/train\\raw_text\\311.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\311.txt into examples\n",
      "data/train\\raw_text\\312.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\312.txt into examples\n",
      "data/train\\raw_text\\313.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\313.txt into examples\n",
      "data/train\\raw_text\\314.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\314.txt into examples\n",
      "data/train\\raw_text\\315.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\315.txt into examples\n",
      "data/train\\raw_text\\316.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\316.txt into examples\n",
      "data/train\\raw_text\\317.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\317.txt into examples\n",
      "data/train\\raw_text\\318.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\318.txt into examples\n",
      "data/train\\raw_text\\319.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\319.txt into examples\n",
      "data/train\\raw_text\\32.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\32.txt into examples\n",
      "data/train\\raw_text\\320.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\320.txt into examples\n",
      "data/train\\raw_text\\321.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\321.txt into examples\n",
      "data/train\\raw_text\\322.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\322.txt into examples\n",
      "data/train\\raw_text\\323.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\323.txt into examples\n",
      "data/train\\raw_text\\324.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\324.txt into examples\n",
      "data/train\\raw_text\\325.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\325.txt into examples\n",
      "data/train\\raw_text\\326.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\326.txt into examples\n",
      "data/train\\raw_text\\327.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\327.txt into examples\n",
      "data/train\\raw_text\\328.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\328.txt into examples\n",
      "data/train\\raw_text\\329.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\329.txt into examples\n",
      "data/train\\raw_text\\33.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\33.txt into examples\n",
      "data/train\\raw_text\\330.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\330.txt into examples\n",
      "data/train\\raw_text\\331.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\331.txt into examples\n",
      "data/train\\raw_text\\332.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\332.txt into examples\n",
      "data/train\\raw_text\\333.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\333.txt into examples\n",
      "data/train\\raw_text\\334.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\334.txt into examples\n",
      "data/train\\raw_text\\335.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\335.txt into examples\n",
      "data/train\\raw_text\\336.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\336.txt into examples\n",
      "data/train\\raw_text\\337.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\337.txt into examples\n",
      "data/train\\raw_text\\338.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\338.txt into examples\n",
      "data/train\\raw_text\\339.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\339.txt into examples\n",
      "data/train\\raw_text\\34.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\34.txt into examples\n",
      "data/train\\raw_text\\340.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\340.txt into examples\n",
      "data/train\\raw_text\\341.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\341.txt into examples\n",
      "data/train\\raw_text\\342.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\342.txt into examples\n",
      "data/train\\raw_text\\343.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\343.txt into examples\n",
      "data/train\\raw_text\\344.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\344.txt into examples\n",
      "data/train\\raw_text\\345.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\345.txt into examples\n",
      "data/train\\raw_text\\346.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\346.txt into examples\n",
      "data/train\\raw_text\\347.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\347.txt into examples\n",
      "data/train\\raw_text\\348.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\348.txt into examples\n",
      "data/train\\raw_text\\349.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\349.txt into examples\n",
      "data/train\\raw_text\\35.txt successfully read and tokenized\n",
      "78\n",
      "Failed at splitting tokens from file data/train\\raw_text\\35.txt into examples\n",
      "data/train\\raw_text\\350.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\350.txt into examples\n",
      "data/train\\raw_text\\351.txt successfully read and tokenized\n",
      "36\n",
      "Failed at splitting tokens from file data/train\\raw_text\\351.txt into examples\n",
      "data/train\\raw_text\\352.txt successfully read and tokenized\n",
      "39\n",
      "Failed at splitting tokens from file data/train\\raw_text\\352.txt into examples\n",
      "data/train\\raw_text\\353.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\353.txt into examples\n",
      "data/train\\raw_text\\354.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\354.txt into examples\n",
      "data/train\\raw_text\\355.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\355.txt into examples\n",
      "data/train\\raw_text\\356.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\356.txt into examples\n",
      "data/train\\raw_text\\357.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\357.txt into examples\n",
      "data/train\\raw_text\\358.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\358.txt into examples\n",
      "data/train\\raw_text\\359.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\359.txt into examples\n",
      "data/train\\raw_text\\36.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\36.txt into examples\n",
      "data/train\\raw_text\\360.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\360.txt into examples\n",
      "data/train\\raw_text\\361.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\361.txt into examples\n",
      "data/train\\raw_text\\362.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\362.txt into examples\n",
      "data/train\\raw_text\\363.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\363.txt into examples\n",
      "data/train\\raw_text\\364.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\364.txt into examples\n",
      "data/train\\raw_text\\365.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\365.txt into examples\n",
      "data/train\\raw_text\\366.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\366.txt into examples\n",
      "data/train\\raw_text\\367.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\367.txt into examples\n",
      "data/train\\raw_text\\368.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\368.txt into examples\n",
      "data/train\\raw_text\\369.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\369.txt into examples\n",
      "data/train\\raw_text\\37.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\37.txt into examples\n",
      "data/train\\raw_text\\370.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\370.txt into examples\n",
      "data/train\\raw_text\\371.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\371.txt into examples\n",
      "data/train\\raw_text\\372.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\372.txt into examples\n",
      "data/train\\raw_text\\373.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\373.txt into examples\n",
      "data/train\\raw_text\\374.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\374.txt into examples\n",
      "data/train\\raw_text\\375.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\375.txt into examples\n",
      "data/train\\raw_text\\376.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\376.txt into examples\n",
      "data/train\\raw_text\\377.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\377.txt into examples\n",
      "data/train\\raw_text\\378.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\378.txt into examples\n",
      "data/train\\raw_text\\379.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\379.txt into examples\n",
      "data/train\\raw_text\\38.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\38.txt into examples\n",
      "data/train\\raw_text\\380.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\380.txt into examples\n",
      "data/train\\raw_text\\381.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\381.txt into examples\n",
      "data/train\\raw_text\\382.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\382.txt into examples\n",
      "data/train\\raw_text\\383.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\383.txt into examples\n",
      "data/train\\raw_text\\384.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\384.txt into examples\n",
      "data/train\\raw_text\\385.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\385.txt into examples\n",
      "data/train\\raw_text\\386.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\386.txt into examples\n",
      "data/train\\raw_text\\387.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\387.txt into examples\n",
      "data/train\\raw_text\\388.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\388.txt into examples\n",
      "data/train\\raw_text\\389.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\389.txt into examples\n",
      "data/train\\raw_text\\39.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\39.txt into examples\n",
      "data/train\\raw_text\\390.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\390.txt into examples\n",
      "data/train\\raw_text\\391.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\391.txt into examples\n",
      "data/train\\raw_text\\392.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\392.txt into examples\n",
      "data/train\\raw_text\\393.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\393.txt into examples\n",
      "data/train\\raw_text\\394.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\394.txt into examples\n",
      "data/train\\raw_text\\395.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\395.txt into examples\n",
      "data/train\\raw_text\\396.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\396.txt into examples\n",
      "data/train\\raw_text\\397.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\397.txt into examples\n",
      "data/train\\raw_text\\398.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\398.txt into examples\n",
      "data/train\\raw_text\\399.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\399.txt into examples\n",
      "data/train\\raw_text\\4.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\4.txt into examples\n",
      "data/train\\raw_text\\40.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\40.txt into examples\n",
      "data/train\\raw_text\\400.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\400.txt into examples\n",
      "data/train\\raw_text\\401.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\401.txt into examples\n",
      "data/train\\raw_text\\402.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\402.txt into examples\n",
      "data/train\\raw_text\\403.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\403.txt into examples\n",
      "data/train\\raw_text\\404.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\404.txt into examples\n",
      "data/train\\raw_text\\405.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\405.txt into examples\n",
      "data/train\\raw_text\\406.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\406.txt into examples\n",
      "data/train\\raw_text\\407.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\407.txt into examples\n",
      "data/train\\raw_text\\408.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\408.txt into examples\n",
      "data/train\\raw_text\\409.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\409.txt into examples\n",
      "data/train\\raw_text\\41.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\41.txt into examples\n",
      "data/train\\raw_text\\410.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\410.txt into examples\n",
      "data/train\\raw_text\\411.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\411.txt into examples\n",
      "data/train\\raw_text\\412.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\412.txt into examples\n",
      "data/train\\raw_text\\413.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\413.txt into examples\n",
      "data/train\\raw_text\\414.txt successfully read and tokenized\n",
      "79\n",
      "Failed at splitting tokens from file data/train\\raw_text\\414.txt into examples\n",
      "data/train\\raw_text\\415.txt successfully read and tokenized\n",
      "34\n",
      "Failed at splitting tokens from file data/train\\raw_text\\415.txt into examples\n",
      "data/train\\raw_text\\416.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\416.txt into examples\n",
      "data/train\\raw_text\\417.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\417.txt into examples\n",
      "data/train\\raw_text\\418.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\418.txt into examples\n",
      "data/train\\raw_text\\419.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\419.txt into examples\n",
      "data/train\\raw_text\\42.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\42.txt into examples\n",
      "data/train\\raw_text\\420.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\420.txt into examples\n",
      "data/train\\raw_text\\421.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\421.txt into examples\n",
      "data/train\\raw_text\\422.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\422.txt into examples\n",
      "data/train\\raw_text\\423.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\423.txt into examples\n",
      "data/train\\raw_text\\424.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\424.txt into examples\n",
      "data/train\\raw_text\\425.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\425.txt into examples\n",
      "data/train\\raw_text\\426.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\426.txt into examples\n",
      "data/train\\raw_text\\427.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\427.txt into examples\n",
      "data/train\\raw_text\\428.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\428.txt into examples\n",
      "data/train\\raw_text\\429.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\429.txt into examples\n",
      "data/train\\raw_text\\43.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\43.txt into examples\n",
      "data/train\\raw_text\\430.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\430.txt into examples\n",
      "data/train\\raw_text\\431.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\431.txt into examples\n",
      "data/train\\raw_text\\432.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\432.txt into examples\n",
      "data/train\\raw_text\\433.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\433.txt into examples\n",
      "data/train\\raw_text\\434.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\434.txt into examples\n",
      "data/train\\raw_text\\435.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\435.txt into examples\n",
      "data/train\\raw_text\\436.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\436.txt into examples\n",
      "data/train\\raw_text\\437.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\437.txt into examples\n",
      "data/train\\raw_text\\438.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\438.txt into examples\n",
      "data/train\\raw_text\\439.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\439.txt into examples\n",
      "data/train\\raw_text\\44.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\44.txt into examples\n",
      "data/train\\raw_text\\440.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\440.txt into examples\n",
      "data/train\\raw_text\\441.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\441.txt into examples\n",
      "data/train\\raw_text\\442.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\442.txt into examples\n",
      "data/train\\raw_text\\443.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\443.txt into examples\n",
      "data/train\\raw_text\\444.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\444.txt into examples\n",
      "data/train\\raw_text\\445.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\445.txt into examples\n",
      "data/train\\raw_text\\446.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\446.txt into examples\n",
      "data/train\\raw_text\\447.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\447.txt into examples\n",
      "data/train\\raw_text\\448.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\448.txt into examples\n",
      "data/train\\raw_text\\449.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\449.txt into examples\n",
      "data/train\\raw_text\\45.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\45.txt into examples\n",
      "data/train\\raw_text\\450.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\450.txt into examples\n",
      "data/train\\raw_text\\451.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\451.txt into examples\n",
      "data/train\\raw_text\\452.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\452.txt into examples\n",
      "data/train\\raw_text\\453.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\453.txt into examples\n",
      "data/train\\raw_text\\454.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\454.txt into examples\n",
      "data/train\\raw_text\\455.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\455.txt into examples\n",
      "data/train\\raw_text\\456.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\456.txt into examples\n",
      "data/train\\raw_text\\457.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\457.txt into examples\n",
      "data/train\\raw_text\\458.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\458.txt into examples\n",
      "data/train\\raw_text\\459.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\459.txt into examples\n",
      "data/train\\raw_text\\46.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\46.txt into examples\n",
      "data/train\\raw_text\\460.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\460.txt into examples\n",
      "data/train\\raw_text\\461.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\461.txt into examples\n",
      "data/train\\raw_text\\462.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\462.txt into examples\n",
      "data/train\\raw_text\\463.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\463.txt into examples\n",
      "data/train\\raw_text\\464.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\464.txt into examples\n",
      "data/train\\raw_text\\465.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\465.txt into examples\n",
      "data/train\\raw_text\\466.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\466.txt into examples\n",
      "data/train\\raw_text\\467.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\467.txt into examples\n",
      "data/train\\raw_text\\468.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\468.txt into examples\n",
      "data/train\\raw_text\\469.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\469.txt into examples\n",
      "data/train\\raw_text\\47.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\47.txt into examples\n",
      "data/train\\raw_text\\470.txt successfully read and tokenized\n",
      "80\n",
      "Failed at splitting tokens from file data/train\\raw_text\\470.txt into examples\n",
      "data/train\\raw_text\\471.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\471.txt into examples\n",
      "data/train\\raw_text\\472.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\472.txt into examples\n",
      "data/train\\raw_text\\473.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\473.txt into examples\n",
      "data/train\\raw_text\\474.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\474.txt into examples\n",
      "data/train\\raw_text\\475.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\475.txt into examples\n",
      "data/train\\raw_text\\476.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\476.txt into examples\n",
      "data/train\\raw_text\\477.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\477.txt into examples\n",
      "data/train\\raw_text\\478.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\478.txt into examples\n",
      "data/train\\raw_text\\479.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\479.txt into examples\n",
      "data/train\\raw_text\\48.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\48.txt into examples\n",
      "data/train\\raw_text\\480.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\480.txt into examples\n",
      "data/train\\raw_text\\481.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\481.txt into examples\n",
      "data/train\\raw_text\\482.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\482.txt into examples\n",
      "data/train\\raw_text\\483.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\483.txt into examples\n",
      "data/train\\raw_text\\484.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\484.txt into examples\n",
      "data/train\\raw_text\\485.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\485.txt into examples\n",
      "data/train\\raw_text\\486.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\486.txt into examples\n",
      "data/train\\raw_text\\487.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\487.txt into examples\n",
      "data/train\\raw_text\\488.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\488.txt into examples\n",
      "data/train\\raw_text\\489.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\489.txt into examples\n",
      "data/train\\raw_text\\49.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\49.txt into examples\n",
      "data/train\\raw_text\\490.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\490.txt into examples\n",
      "data/train\\raw_text\\491.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\491.txt into examples\n",
      "data/train\\raw_text\\492.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\492.txt into examples\n",
      "data/train\\raw_text\\493.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\493.txt into examples\n",
      "data/train\\raw_text\\494.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\494.txt into examples\n",
      "data/train\\raw_text\\495.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\495.txt into examples\n",
      "data/train\\raw_text\\496.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\496.txt into examples\n",
      "data/train\\raw_text\\497.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\497.txt into examples\n",
      "data/train\\raw_text\\498.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\498.txt into examples\n",
      "data/train\\raw_text\\499.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\499.txt into examples\n",
      "data/train\\raw_text\\5.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\5.txt into examples\n",
      "data/train\\raw_text\\50.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\50.txt into examples\n",
      "data/train\\raw_text\\500.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\500.txt into examples\n",
      "data/train\\raw_text\\501.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\501.txt into examples\n",
      "data/train\\raw_text\\502.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\502.txt into examples\n",
      "data/train\\raw_text\\503.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\503.txt into examples\n",
      "data/train\\raw_text\\504.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\504.txt into examples\n",
      "data/train\\raw_text\\505.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\505.txt into examples\n",
      "data/train\\raw_text\\506.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\506.txt into examples\n",
      "data/train\\raw_text\\507.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\507.txt into examples\n",
      "data/train\\raw_text\\508.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\508.txt into examples\n",
      "data/train\\raw_text\\509.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\509.txt into examples\n",
      "data/train\\raw_text\\51.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\51.txt into examples\n",
      "data/train\\raw_text\\510.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\510.txt into examples\n",
      "data/train\\raw_text\\511.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\511.txt into examples\n",
      "data/train\\raw_text\\512.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\512.txt into examples\n",
      "data/train\\raw_text\\513.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\513.txt into examples\n",
      "data/train\\raw_text\\514.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\514.txt into examples\n",
      "data/train\\raw_text\\515.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\515.txt into examples\n",
      "data/train\\raw_text\\516.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\516.txt into examples\n",
      "data/train\\raw_text\\517.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\517.txt into examples\n",
      "data/train\\raw_text\\518.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\518.txt into examples\n",
      "data/train\\raw_text\\519.txt successfully read and tokenized\n",
      "78\n",
      "Failed at splitting tokens from file data/train\\raw_text\\519.txt into examples\n",
      "data/train\\raw_text\\52.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\52.txt into examples\n",
      "data/train\\raw_text\\520.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\520.txt into examples\n",
      "data/train\\raw_text\\521.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\521.txt into examples\n",
      "data/train\\raw_text\\522.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\522.txt into examples\n",
      "data/train\\raw_text\\523.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\523.txt into examples\n",
      "data/train\\raw_text\\524.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\524.txt into examples\n",
      "data/train\\raw_text\\525.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\525.txt into examples\n",
      "data/train\\raw_text\\526.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\526.txt into examples\n",
      "data/train\\raw_text\\527.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\527.txt into examples\n",
      "data/train\\raw_text\\528.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\528.txt into examples\n",
      "data/train\\raw_text\\529.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\529.txt into examples\n",
      "data/train\\raw_text\\53.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\53.txt into examples\n",
      "data/train\\raw_text\\530.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\530.txt into examples\n",
      "data/train\\raw_text\\531.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\531.txt into examples\n",
      "data/train\\raw_text\\532.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\532.txt into examples\n",
      "data/train\\raw_text\\533.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\533.txt into examples\n",
      "data/train\\raw_text\\534.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\534.txt into examples\n",
      "data/train\\raw_text\\535.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\535.txt into examples\n",
      "data/train\\raw_text\\536.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\536.txt into examples\n",
      "data/train\\raw_text\\537.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\537.txt into examples\n",
      "data/train\\raw_text\\538.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\538.txt into examples\n",
      "data/train\\raw_text\\539.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\539.txt into examples\n",
      "data/train\\raw_text\\54.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\54.txt into examples\n",
      "data/train\\raw_text\\540.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\540.txt into examples\n",
      "data/train\\raw_text\\541.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\541.txt into examples\n",
      "data/train\\raw_text\\542.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\542.txt into examples\n",
      "data/train\\raw_text\\543.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\543.txt into examples\n",
      "data/train\\raw_text\\544.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\544.txt into examples\n",
      "data/train\\raw_text\\545.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\545.txt into examples\n",
      "data/train\\raw_text\\546.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\546.txt into examples\n",
      "data/train\\raw_text\\547.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\547.txt into examples\n",
      "data/train\\raw_text\\548.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\548.txt into examples\n",
      "data/train\\raw_text\\549.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\549.txt into examples\n",
      "data/train\\raw_text\\55.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\55.txt into examples\n",
      "data/train\\raw_text\\550.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\550.txt into examples\n",
      "data/train\\raw_text\\551.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\551.txt into examples\n",
      "data/train\\raw_text\\552.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\552.txt into examples\n",
      "data/train\\raw_text\\553.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\553.txt into examples\n",
      "data/train\\raw_text\\554.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\554.txt into examples\n",
      "data/train\\raw_text\\555.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\555.txt into examples\n",
      "data/train\\raw_text\\556.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\556.txt into examples\n",
      "data/train\\raw_text\\557.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\557.txt into examples\n",
      "data/train\\raw_text\\558.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\558.txt into examples\n",
      "data/train\\raw_text\\559.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\559.txt into examples\n",
      "data/train\\raw_text\\56.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\56.txt into examples\n",
      "data/train\\raw_text\\560.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\560.txt into examples\n",
      "data/train\\raw_text\\561.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\561.txt into examples\n",
      "data/train\\raw_text\\562.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\562.txt into examples\n",
      "data/train\\raw_text\\563.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\563.txt into examples\n",
      "data/train\\raw_text\\564.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\564.txt into examples\n",
      "data/train\\raw_text\\565.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\565.txt into examples\n",
      "data/train\\raw_text\\566.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\566.txt into examples\n",
      "data/train\\raw_text\\567.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\567.txt into examples\n",
      "data/train\\raw_text\\568.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\568.txt into examples\n",
      "data/train\\raw_text\\569.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\569.txt into examples\n",
      "data/train\\raw_text\\57.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\57.txt into examples\n",
      "data/train\\raw_text\\570.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\570.txt into examples\n",
      "data/train\\raw_text\\571.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\571.txt into examples\n",
      "data/train\\raw_text\\572.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\572.txt into examples\n",
      "data/train\\raw_text\\573.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\573.txt into examples\n",
      "data/train\\raw_text\\574.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\574.txt into examples\n",
      "data/train\\raw_text\\575.txt successfully read and tokenized\n",
      "32\n",
      "Failed at splitting tokens from file data/train\\raw_text\\575.txt into examples\n",
      "data/train\\raw_text\\576.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\576.txt into examples\n",
      "data/train\\raw_text\\577.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\577.txt into examples\n",
      "data/train\\raw_text\\578.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\578.txt into examples\n",
      "data/train\\raw_text\\579.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\579.txt into examples\n",
      "data/train\\raw_text\\58.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\58.txt into examples\n",
      "data/train\\raw_text\\580.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\580.txt into examples\n",
      "data/train\\raw_text\\581.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\581.txt into examples\n",
      "data/train\\raw_text\\582.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\582.txt into examples\n",
      "data/train\\raw_text\\583.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\583.txt into examples\n",
      "data/train\\raw_text\\584.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\584.txt into examples\n",
      "data/train\\raw_text\\585.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\585.txt into examples\n",
      "data/train\\raw_text\\586.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\586.txt into examples\n",
      "data/train\\raw_text\\587.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\587.txt into examples\n",
      "data/train\\raw_text\\588.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\588.txt into examples\n",
      "data/train\\raw_text\\589.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\589.txt into examples\n",
      "data/train\\raw_text\\59.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\59.txt into examples\n",
      "data/train\\raw_text\\590.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\590.txt into examples\n",
      "data/train\\raw_text\\591.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\591.txt into examples\n",
      "data/train\\raw_text\\592.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\592.txt into examples\n",
      "data/train\\raw_text\\593.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\593.txt into examples\n",
      "data/train\\raw_text\\594.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\594.txt into examples\n",
      "data/train\\raw_text\\595.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\595.txt into examples\n",
      "data/train\\raw_text\\596.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\596.txt into examples\n",
      "data/train\\raw_text\\597.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\597.txt into examples\n",
      "data/train\\raw_text\\598.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\598.txt into examples\n",
      "data/train\\raw_text\\599.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\599.txt into examples\n",
      "data/train\\raw_text\\6.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\6.txt into examples\n",
      "data/train\\raw_text\\60.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\60.txt into examples\n",
      "data/train\\raw_text\\600.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\600.txt into examples\n",
      "data/train\\raw_text\\601.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\601.txt into examples\n",
      "data/train\\raw_text\\602.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\602.txt into examples\n",
      "data/train\\raw_text\\603.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\603.txt into examples\n",
      "data/train\\raw_text\\604.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\604.txt into examples\n",
      "data/train\\raw_text\\605.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\605.txt into examples\n",
      "data/train\\raw_text\\606.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\606.txt into examples\n",
      "data/train\\raw_text\\607.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\607.txt into examples\n",
      "data/train\\raw_text\\608.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\608.txt into examples\n",
      "data/train\\raw_text\\609.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\609.txt into examples\n",
      "data/train\\raw_text\\61.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\61.txt into examples\n",
      "data/train\\raw_text\\610.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\610.txt into examples\n",
      "data/train\\raw_text\\611.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\611.txt into examples\n",
      "data/train\\raw_text\\612.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\612.txt into examples\n",
      "data/train\\raw_text\\613.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\613.txt into examples\n",
      "data/train\\raw_text\\614.txt successfully read and tokenized\n",
      "32\n",
      "Failed at splitting tokens from file data/train\\raw_text\\614.txt into examples\n",
      "data/train\\raw_text\\615.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\615.txt into examples\n",
      "data/train\\raw_text\\616.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\616.txt into examples\n",
      "data/train\\raw_text\\617.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\617.txt into examples\n",
      "data/train\\raw_text\\618.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\618.txt into examples\n",
      "data/train\\raw_text\\619.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\619.txt into examples\n",
      "data/train\\raw_text\\62.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\62.txt into examples\n",
      "data/train\\raw_text\\620.txt successfully read and tokenized\n",
      "81\n",
      "Failed at splitting tokens from file data/train\\raw_text\\620.txt into examples\n",
      "data/train\\raw_text\\621.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\621.txt into examples\n",
      "data/train\\raw_text\\622.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\622.txt into examples\n",
      "data/train\\raw_text\\623.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\623.txt into examples\n",
      "data/train\\raw_text\\624.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\624.txt into examples\n",
      "data/train\\raw_text\\625.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\625.txt into examples\n",
      "data/train\\raw_text\\626.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\626.txt into examples\n",
      "data/train\\raw_text\\627.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\627.txt into examples\n",
      "data/train\\raw_text\\628.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\628.txt into examples\n",
      "data/train\\raw_text\\629.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\629.txt into examples\n",
      "data/train\\raw_text\\63.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\63.txt into examples\n",
      "data/train\\raw_text\\630.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\630.txt into examples\n",
      "data/train\\raw_text\\631.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\631.txt into examples\n",
      "data/train\\raw_text\\632.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\632.txt into examples\n",
      "data/train\\raw_text\\633.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\633.txt into examples\n",
      "data/train\\raw_text\\634.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\634.txt into examples\n",
      "data/train\\raw_text\\635.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\635.txt into examples\n",
      "data/train\\raw_text\\636.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\636.txt into examples\n",
      "data/train\\raw_text\\637.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\637.txt into examples\n",
      "data/train\\raw_text\\638.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\638.txt into examples\n",
      "data/train\\raw_text\\639.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\639.txt into examples\n",
      "data/train\\raw_text\\64.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\64.txt into examples\n",
      "data/train\\raw_text\\640.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\640.txt into examples\n",
      "data/train\\raw_text\\641.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\641.txt into examples\n",
      "data/train\\raw_text\\642.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\642.txt into examples\n",
      "data/train\\raw_text\\643.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\643.txt into examples\n",
      "data/train\\raw_text\\644.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\644.txt into examples\n",
      "data/train\\raw_text\\645.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\645.txt into examples\n",
      "data/train\\raw_text\\646.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\646.txt into examples\n",
      "data/train\\raw_text\\647.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\647.txt into examples\n",
      "data/train\\raw_text\\648.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\648.txt into examples\n",
      "data/train\\raw_text\\649.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\649.txt into examples\n",
      "data/train\\raw_text\\65.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\65.txt into examples\n",
      "data/train\\raw_text\\650.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\650.txt into examples\n",
      "data/train\\raw_text\\651.txt successfully read and tokenized\n",
      "78\n",
      "Failed at splitting tokens from file data/train\\raw_text\\651.txt into examples\n",
      "data/train\\raw_text\\652.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\652.txt into examples\n",
      "data/train\\raw_text\\653.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\653.txt into examples\n",
      "data/train\\raw_text\\654.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\654.txt into examples\n",
      "data/train\\raw_text\\655.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\655.txt into examples\n",
      "data/train\\raw_text\\656.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\656.txt into examples\n",
      "data/train\\raw_text\\657.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\657.txt into examples\n",
      "data/train\\raw_text\\658.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\658.txt into examples\n",
      "data/train\\raw_text\\659.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\659.txt into examples\n",
      "data/train\\raw_text\\66.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\66.txt into examples\n",
      "data/train\\raw_text\\660.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\660.txt into examples\n",
      "data/train\\raw_text\\661.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\661.txt into examples\n",
      "data/train\\raw_text\\662.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\662.txt into examples\n",
      "data/train\\raw_text\\663.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\663.txt into examples\n",
      "data/train\\raw_text\\664.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\664.txt into examples\n",
      "data/train\\raw_text\\665.txt successfully read and tokenized\n",
      "76\n",
      "Failed at splitting tokens from file data/train\\raw_text\\665.txt into examples\n",
      "data/train\\raw_text\\666.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\666.txt into examples\n",
      "data/train\\raw_text\\667.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\667.txt into examples\n",
      "data/train\\raw_text\\668.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\668.txt into examples\n",
      "data/train\\raw_text\\669.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\669.txt into examples\n",
      "data/train\\raw_text\\67.txt successfully read and tokenized\n",
      "30\n",
      "Failed at splitting tokens from file data/train\\raw_text\\67.txt into examples\n",
      "data/train\\raw_text\\670.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\670.txt into examples\n",
      "data/train\\raw_text\\671.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\671.txt into examples\n",
      "data/train\\raw_text\\672.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\672.txt into examples\n",
      "data/train\\raw_text\\673.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\673.txt into examples\n",
      "data/train\\raw_text\\674.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\674.txt into examples\n",
      "data/train\\raw_text\\675.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\675.txt into examples\n",
      "data/train\\raw_text\\676.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\676.txt into examples\n",
      "data/train\\raw_text\\677.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\677.txt into examples\n",
      "data/train\\raw_text\\678.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\678.txt into examples\n",
      "data/train\\raw_text\\679.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\679.txt into examples\n",
      "data/train\\raw_text\\68.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\68.txt into examples\n",
      "data/train\\raw_text\\680.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\680.txt into examples\n",
      "data/train\\raw_text\\681.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\681.txt into examples\n",
      "data/train\\raw_text\\682.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\682.txt into examples\n",
      "data/train\\raw_text\\683.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\683.txt into examples\n",
      "data/train\\raw_text\\684.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\684.txt into examples\n",
      "data/train\\raw_text\\685.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\685.txt into examples\n",
      "data/train\\raw_text\\686.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\686.txt into examples\n",
      "data/train\\raw_text\\687.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\687.txt into examples\n",
      "data/train\\raw_text\\688.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\688.txt into examples\n",
      "data/train\\raw_text\\689.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\689.txt into examples\n",
      "data/train\\raw_text\\69.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\69.txt into examples\n",
      "data/train\\raw_text\\690.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\690.txt into examples\n",
      "data/train\\raw_text\\691.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\691.txt into examples\n",
      "data/train\\raw_text\\692.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\692.txt into examples\n",
      "data/train\\raw_text\\693.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\693.txt into examples\n",
      "data/train\\raw_text\\694.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\694.txt into examples\n",
      "data/train\\raw_text\\695.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\695.txt into examples\n",
      "data/train\\raw_text\\696.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\696.txt into examples\n",
      "data/train\\raw_text\\697.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\697.txt into examples\n",
      "data/train\\raw_text\\698.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\698.txt into examples\n",
      "data/train\\raw_text\\699.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\699.txt into examples\n",
      "data/train\\raw_text\\7.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\7.txt into examples\n",
      "data/train\\raw_text\\70.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\70.txt into examples\n",
      "data/train\\raw_text\\700.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\700.txt into examples\n",
      "data/train\\raw_text\\701.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\701.txt into examples\n",
      "data/train\\raw_text\\702.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\702.txt into examples\n",
      "data/train\\raw_text\\703.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\703.txt into examples\n",
      "data/train\\raw_text\\704.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\704.txt into examples\n",
      "data/train\\raw_text\\705.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\705.txt into examples\n",
      "data/train\\raw_text\\706.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\706.txt into examples\n",
      "data/train\\raw_text\\707.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\707.txt into examples\n",
      "data/train\\raw_text\\708.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\708.txt into examples\n",
      "data/train\\raw_text\\709.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\709.txt into examples\n",
      "data/train\\raw_text\\71.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\71.txt into examples\n",
      "data/train\\raw_text\\710.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\710.txt into examples\n",
      "data/train\\raw_text\\711.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\711.txt into examples\n",
      "data/train\\raw_text\\712.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\712.txt into examples\n",
      "data/train\\raw_text\\713.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\713.txt into examples\n",
      "data/train\\raw_text\\714.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\714.txt into examples\n",
      "data/train\\raw_text\\715.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\715.txt into examples\n",
      "data/train\\raw_text\\716.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\716.txt into examples\n",
      "data/train\\raw_text\\717.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\717.txt into examples\n",
      "data/train\\raw_text\\718.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\718.txt into examples\n",
      "data/train\\raw_text\\719.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\719.txt into examples\n",
      "data/train\\raw_text\\72.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\72.txt into examples\n",
      "data/train\\raw_text\\720.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\720.txt into examples\n",
      "data/train\\raw_text\\721.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\721.txt into examples\n",
      "data/train\\raw_text\\722.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\722.txt into examples\n",
      "data/train\\raw_text\\723.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\723.txt into examples\n",
      "data/train\\raw_text\\724.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\724.txt into examples\n",
      "data/train\\raw_text\\725.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\725.txt into examples\n",
      "data/train\\raw_text\\726.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\726.txt into examples\n",
      "data/train\\raw_text\\727.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\727.txt into examples\n",
      "data/train\\raw_text\\728.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\728.txt into examples\n",
      "data/train\\raw_text\\729.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\729.txt into examples\n",
      "data/train\\raw_text\\73.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\73.txt into examples\n",
      "data/train\\raw_text\\730.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\730.txt into examples\n",
      "data/train\\raw_text\\731.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\731.txt into examples\n",
      "data/train\\raw_text\\732.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\732.txt into examples\n",
      "data/train\\raw_text\\733.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\733.txt into examples\n",
      "data/train\\raw_text\\734.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\734.txt into examples\n",
      "data/train\\raw_text\\735.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\735.txt into examples\n",
      "data/train\\raw_text\\736.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\736.txt into examples\n",
      "data/train\\raw_text\\737.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\737.txt into examples\n",
      "data/train\\raw_text\\738.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\738.txt into examples\n",
      "data/train\\raw_text\\739.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\739.txt into examples\n",
      "data/train\\raw_text\\74.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\74.txt into examples\n",
      "data/train\\raw_text\\740.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\740.txt into examples\n",
      "data/train\\raw_text\\741.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\741.txt into examples\n",
      "data/train\\raw_text\\742.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\742.txt into examples\n",
      "data/train\\raw_text\\743.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\743.txt into examples\n",
      "data/train\\raw_text\\744.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\744.txt into examples\n",
      "data/train\\raw_text\\745.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\745.txt into examples\n",
      "data/train\\raw_text\\746.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\746.txt into examples\n",
      "data/train\\raw_text\\747.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\747.txt into examples\n",
      "data/train\\raw_text\\748.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\748.txt into examples\n",
      "data/train\\raw_text\\749.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\749.txt into examples\n",
      "data/train\\raw_text\\75.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\75.txt into examples\n",
      "data/train\\raw_text\\750.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\750.txt into examples\n",
      "data/train\\raw_text\\751.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\751.txt into examples\n",
      "data/train\\raw_text\\752.txt successfully read and tokenized\n",
      "76\n",
      "Failed at splitting tokens from file data/train\\raw_text\\752.txt into examples\n",
      "data/train\\raw_text\\753.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\753.txt into examples\n",
      "data/train\\raw_text\\754.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\754.txt into examples\n",
      "data/train\\raw_text\\755.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\755.txt into examples\n",
      "data/train\\raw_text\\756.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\756.txt into examples\n",
      "data/train\\raw_text\\757.txt successfully read and tokenized\n",
      "80\n",
      "Failed at splitting tokens from file data/train\\raw_text\\757.txt into examples\n",
      "data/train\\raw_text\\758.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\758.txt into examples\n",
      "data/train\\raw_text\\759.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\759.txt into examples\n",
      "data/train\\raw_text\\76.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\76.txt into examples\n",
      "data/train\\raw_text\\760.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\760.txt into examples\n",
      "data/train\\raw_text\\761.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\761.txt into examples\n",
      "data/train\\raw_text\\762.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\762.txt into examples\n",
      "data/train\\raw_text\\763.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\763.txt into examples\n",
      "data/train\\raw_text\\764.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\764.txt into examples\n",
      "data/train\\raw_text\\765.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\765.txt into examples\n",
      "data/train\\raw_text\\766.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\766.txt into examples\n",
      "data/train\\raw_text\\767.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\767.txt into examples\n",
      "data/train\\raw_text\\768.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\768.txt into examples\n",
      "data/train\\raw_text\\769.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\769.txt into examples\n",
      "data/train\\raw_text\\77.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\77.txt into examples\n",
      "data/train\\raw_text\\770.txt successfully read and tokenized\n",
      "82\n",
      "Failed at splitting tokens from file data/train\\raw_text\\770.txt into examples\n",
      "data/train\\raw_text\\771.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\771.txt into examples\n",
      "data/train\\raw_text\\772.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\772.txt into examples\n",
      "data/train\\raw_text\\773.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\773.txt into examples\n",
      "data/train\\raw_text\\774.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\774.txt into examples\n",
      "data/train\\raw_text\\775.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\775.txt into examples\n",
      "data/train\\raw_text\\776.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\776.txt into examples\n",
      "data/train\\raw_text\\777.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\777.txt into examples\n",
      "data/train\\raw_text\\778.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\778.txt into examples\n",
      "data/train\\raw_text\\779.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\779.txt into examples\n",
      "data/train\\raw_text\\78.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\78.txt into examples\n",
      "data/train\\raw_text\\780.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\780.txt into examples\n",
      "data/train\\raw_text\\781.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\781.txt into examples\n",
      "data/train\\raw_text\\782.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\782.txt into examples\n",
      "data/train\\raw_text\\783.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\783.txt into examples\n",
      "data/train\\raw_text\\784.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\784.txt into examples\n",
      "data/train\\raw_text\\785.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\785.txt into examples\n",
      "data/train\\raw_text\\786.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\786.txt into examples\n",
      "data/train\\raw_text\\787.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\787.txt into examples\n",
      "data/train\\raw_text\\788.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\788.txt into examples\n",
      "data/train\\raw_text\\789.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\789.txt into examples\n",
      "data/train\\raw_text\\79.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\79.txt into examples\n",
      "data/train\\raw_text\\790.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\790.txt into examples\n",
      "data/train\\raw_text\\791.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\791.txt into examples\n",
      "data/train\\raw_text\\792.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\792.txt into examples\n",
      "data/train\\raw_text\\793.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\793.txt into examples\n",
      "data/train\\raw_text\\794.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\794.txt into examples\n",
      "data/train\\raw_text\\795.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\795.txt into examples\n",
      "data/train\\raw_text\\796.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\796.txt into examples\n",
      "data/train\\raw_text\\797.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\797.txt into examples\n",
      "data/train\\raw_text\\798.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\798.txt into examples\n",
      "data/train\\raw_text\\799.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\799.txt into examples\n",
      "data/train\\raw_text\\8.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\8.txt into examples\n",
      "data/train\\raw_text\\80.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\80.txt into examples\n",
      "data/train\\raw_text\\800.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\800.txt into examples\n",
      "data/train\\raw_text\\801.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\801.txt into examples\n",
      "data/train\\raw_text\\802.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\802.txt into examples\n",
      "data/train\\raw_text\\803.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\803.txt into examples\n",
      "data/train\\raw_text\\804.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\804.txt into examples\n",
      "data/train\\raw_text\\805.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\805.txt into examples\n",
      "data/train\\raw_text\\806.txt successfully read and tokenized\n",
      "35\n",
      "Failed at splitting tokens from file data/train\\raw_text\\806.txt into examples\n",
      "data/train\\raw_text\\807.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\807.txt into examples\n",
      "data/train\\raw_text\\808.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\808.txt into examples\n",
      "data/train\\raw_text\\809.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\809.txt into examples\n",
      "data/train\\raw_text\\81.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\81.txt into examples\n",
      "data/train\\raw_text\\810.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\810.txt into examples\n",
      "data/train\\raw_text\\811.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\811.txt into examples\n",
      "data/train\\raw_text\\812.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\812.txt into examples\n",
      "data/train\\raw_text\\813.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\813.txt into examples\n",
      "data/train\\raw_text\\814.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\814.txt into examples\n",
      "data/train\\raw_text\\815.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\815.txt into examples\n",
      "data/train\\raw_text\\816.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\816.txt into examples\n",
      "data/train\\raw_text\\817.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\817.txt into examples\n",
      "data/train\\raw_text\\818.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\818.txt into examples\n",
      "data/train\\raw_text\\819.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\819.txt into examples\n",
      "data/train\\raw_text\\82.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\82.txt into examples\n",
      "data/train\\raw_text\\820.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\820.txt into examples\n",
      "data/train\\raw_text\\821.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\821.txt into examples\n",
      "data/train\\raw_text\\822.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\822.txt into examples\n",
      "data/train\\raw_text\\823.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\823.txt into examples\n",
      "data/train\\raw_text\\824.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\824.txt into examples\n",
      "data/train\\raw_text\\825.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\825.txt into examples\n",
      "data/train\\raw_text\\826.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\826.txt into examples\n",
      "data/train\\raw_text\\827.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\827.txt into examples\n",
      "data/train\\raw_text\\828.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\828.txt into examples\n",
      "data/train\\raw_text\\829.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\829.txt into examples\n",
      "data/train\\raw_text\\83.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\83.txt into examples\n",
      "data/train\\raw_text\\830.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\830.txt into examples\n",
      "data/train\\raw_text\\831.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\831.txt into examples\n",
      "data/train\\raw_text\\832.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\832.txt into examples\n",
      "data/train\\raw_text\\833.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\833.txt into examples\n",
      "data/train\\raw_text\\834.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\834.txt into examples\n",
      "data/train\\raw_text\\835.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\835.txt into examples\n",
      "data/train\\raw_text\\836.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\836.txt into examples\n",
      "data/train\\raw_text\\837.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\837.txt into examples\n",
      "data/train\\raw_text\\838.txt successfully read and tokenized\n",
      "41\n",
      "Failed at splitting tokens from file data/train\\raw_text\\838.txt into examples\n",
      "data/train\\raw_text\\839.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\839.txt into examples\n",
      "data/train\\raw_text\\84.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\84.txt into examples\n",
      "data/train\\raw_text\\840.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\840.txt into examples\n",
      "data/train\\raw_text\\841.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\841.txt into examples\n",
      "data/train\\raw_text\\842.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\842.txt into examples\n",
      "data/train\\raw_text\\843.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\843.txt into examples\n",
      "data/train\\raw_text\\844.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\844.txt into examples\n",
      "data/train\\raw_text\\845.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\845.txt into examples\n",
      "data/train\\raw_text\\846.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\846.txt into examples\n",
      "data/train\\raw_text\\847.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\847.txt into examples\n",
      "data/train\\raw_text\\848.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\848.txt into examples\n",
      "data/train\\raw_text\\849.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\849.txt into examples\n",
      "data/train\\raw_text\\85.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\85.txt into examples\n",
      "data/train\\raw_text\\850.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\850.txt into examples\n",
      "data/train\\raw_text\\851.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\851.txt into examples\n",
      "data/train\\raw_text\\852.txt successfully read and tokenized\n",
      "39\n",
      "Failed at splitting tokens from file data/train\\raw_text\\852.txt into examples\n",
      "data/train\\raw_text\\853.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\853.txt into examples\n",
      "data/train\\raw_text\\854.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\854.txt into examples\n",
      "data/train\\raw_text\\855.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\855.txt into examples\n",
      "data/train\\raw_text\\856.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\856.txt into examples\n",
      "data/train\\raw_text\\857.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\857.txt into examples\n",
      "data/train\\raw_text\\858.txt successfully read and tokenized\n",
      "36\n",
      "Failed at splitting tokens from file data/train\\raw_text\\858.txt into examples\n",
      "data/train\\raw_text\\859.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\859.txt into examples\n",
      "data/train\\raw_text\\86.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\86.txt into examples\n",
      "data/train\\raw_text\\860.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\860.txt into examples\n",
      "data/train\\raw_text\\861.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\861.txt into examples\n",
      "data/train\\raw_text\\862.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\862.txt into examples\n",
      "data/train\\raw_text\\863.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\863.txt into examples\n",
      "data/train\\raw_text\\864.txt successfully read and tokenized\n",
      "42\n",
      "Failed at splitting tokens from file data/train\\raw_text\\864.txt into examples\n",
      "data/train\\raw_text\\865.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\865.txt into examples\n",
      "data/train\\raw_text\\866.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\866.txt into examples\n",
      "data/train\\raw_text\\867.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\867.txt into examples\n",
      "data/train\\raw_text\\868.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\868.txt into examples\n",
      "data/train\\raw_text\\869.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\869.txt into examples\n",
      "data/train\\raw_text\\87.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\87.txt into examples\n",
      "data/train\\raw_text\\870.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\870.txt into examples\n",
      "data/train\\raw_text\\871.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\871.txt into examples\n",
      "data/train\\raw_text\\872.txt successfully read and tokenized\n",
      "34\n",
      "Failed at splitting tokens from file data/train\\raw_text\\872.txt into examples\n",
      "data/train\\raw_text\\873.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\873.txt into examples\n",
      "data/train\\raw_text\\874.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\874.txt into examples\n",
      "data/train\\raw_text\\875.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\875.txt into examples\n",
      "data/train\\raw_text\\876.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\876.txt into examples\n",
      "data/train\\raw_text\\877.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\877.txt into examples\n",
      "data/train\\raw_text\\878.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\878.txt into examples\n",
      "data/train\\raw_text\\879.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\879.txt into examples\n",
      "data/train\\raw_text\\88.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\88.txt into examples\n",
      "data/train\\raw_text\\880.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\880.txt into examples\n",
      "data/train\\raw_text\\881.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\881.txt into examples\n",
      "data/train\\raw_text\\882.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\882.txt into examples\n",
      "data/train\\raw_text\\883.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\883.txt into examples\n",
      "data/train\\raw_text\\884.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\884.txt into examples\n",
      "data/train\\raw_text\\885.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\885.txt into examples\n",
      "data/train\\raw_text\\886.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\886.txt into examples\n",
      "data/train\\raw_text\\887.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\887.txt into examples\n",
      "data/train\\raw_text\\888.txt successfully read and tokenized\n",
      "74\n",
      "Failed at splitting tokens from file data/train\\raw_text\\888.txt into examples\n",
      "data/train\\raw_text\\889.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\889.txt into examples\n",
      "data/train\\raw_text\\89.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\89.txt into examples\n",
      "data/train\\raw_text\\890.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\890.txt into examples\n",
      "data/train\\raw_text\\891.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\891.txt into examples\n",
      "data/train\\raw_text\\892.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\892.txt into examples\n",
      "data/train\\raw_text\\893.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\893.txt into examples\n",
      "data/train\\raw_text\\894.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\894.txt into examples\n",
      "data/train\\raw_text\\895.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\895.txt into examples\n",
      "data/train\\raw_text\\896.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\896.txt into examples\n",
      "data/train\\raw_text\\897.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\897.txt into examples\n",
      "data/train\\raw_text\\898.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\898.txt into examples\n",
      "data/train\\raw_text\\899.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\899.txt into examples\n",
      "data/train\\raw_text\\9.txt successfully read and tokenized\n",
      "77\n",
      "Failed at splitting tokens from file data/train\\raw_text\\9.txt into examples\n",
      "data/train\\raw_text\\90.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\90.txt into examples\n",
      "data/train\\raw_text\\900.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\900.txt into examples\n",
      "data/train\\raw_text\\901.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\901.txt into examples\n",
      "data/train\\raw_text\\902.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\902.txt into examples\n",
      "data/train\\raw_text\\903.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\903.txt into examples\n",
      "data/train\\raw_text\\904.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\904.txt into examples\n",
      "data/train\\raw_text\\905.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\905.txt into examples\n",
      "data/train\\raw_text\\906.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\906.txt into examples\n",
      "data/train\\raw_text\\907.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\907.txt into examples\n",
      "data/train\\raw_text\\908.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\908.txt into examples\n",
      "data/train\\raw_text\\909.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\909.txt into examples\n",
      "data/train\\raw_text\\91.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\91.txt into examples\n",
      "data/train\\raw_text\\910.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\910.txt into examples\n",
      "data/train\\raw_text\\911.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\911.txt into examples\n",
      "data/train\\raw_text\\912.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\912.txt into examples\n",
      "data/train\\raw_text\\913.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\913.txt into examples\n",
      "data/train\\raw_text\\914.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\914.txt into examples\n",
      "data/train\\raw_text\\915.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\915.txt into examples\n",
      "data/train\\raw_text\\916.txt successfully read and tokenized\n",
      "79\n",
      "Failed at splitting tokens from file data/train\\raw_text\\916.txt into examples\n",
      "data/train\\raw_text\\917.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\917.txt into examples\n",
      "data/train\\raw_text\\918.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\918.txt into examples\n",
      "data/train\\raw_text\\919.txt successfully read and tokenized\n",
      "44\n",
      "Failed at splitting tokens from file data/train\\raw_text\\919.txt into examples\n",
      "data/train\\raw_text\\92.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\92.txt into examples\n",
      "data/train\\raw_text\\920.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\920.txt into examples\n",
      "data/train\\raw_text\\921.txt successfully read and tokenized\n",
      "62\n",
      "Failed at splitting tokens from file data/train\\raw_text\\921.txt into examples\n",
      "data/train\\raw_text\\922.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\922.txt into examples\n",
      "data/train\\raw_text\\923.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\923.txt into examples\n",
      "data/train\\raw_text\\924.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\924.txt into examples\n",
      "data/train\\raw_text\\925.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\925.txt into examples\n",
      "data/train\\raw_text\\926.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\926.txt into examples\n",
      "data/train\\raw_text\\927.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\927.txt into examples\n",
      "data/train\\raw_text\\928.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\928.txt into examples\n",
      "data/train\\raw_text\\929.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\929.txt into examples\n",
      "data/train\\raw_text\\93.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\93.txt into examples\n",
      "data/train\\raw_text\\930.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\930.txt into examples\n",
      "data/train\\raw_text\\931.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\931.txt into examples\n",
      "data/train\\raw_text\\932.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\932.txt into examples\n",
      "data/train\\raw_text\\933.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\933.txt into examples\n",
      "data/train\\raw_text\\934.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\934.txt into examples\n",
      "data/train\\raw_text\\935.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\935.txt into examples\n",
      "data/train\\raw_text\\936.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\936.txt into examples\n",
      "data/train\\raw_text\\937.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\937.txt into examples\n",
      "data/train\\raw_text\\938.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\938.txt into examples\n",
      "data/train\\raw_text\\939.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\939.txt into examples\n",
      "data/train\\raw_text\\94.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\94.txt into examples\n",
      "data/train\\raw_text\\940.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\940.txt into examples\n",
      "data/train\\raw_text\\941.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\941.txt into examples\n",
      "data/train\\raw_text\\942.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\942.txt into examples\n",
      "data/train\\raw_text\\943.txt successfully read and tokenized\n",
      "43\n",
      "Failed at splitting tokens from file data/train\\raw_text\\943.txt into examples\n",
      "data/train\\raw_text\\944.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\944.txt into examples\n",
      "data/train\\raw_text\\945.txt successfully read and tokenized\n",
      "72\n",
      "Failed at splitting tokens from file data/train\\raw_text\\945.txt into examples\n",
      "data/train\\raw_text\\946.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\946.txt into examples\n",
      "data/train\\raw_text\\947.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\947.txt into examples\n",
      "data/train\\raw_text\\948.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\948.txt into examples\n",
      "data/train\\raw_text\\949.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\949.txt into examples\n",
      "data/train\\raw_text\\95.txt successfully read and tokenized\n",
      "70\n",
      "Failed at splitting tokens from file data/train\\raw_text\\95.txt into examples\n",
      "data/train\\raw_text\\950.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\950.txt into examples\n",
      "data/train\\raw_text\\951.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\951.txt into examples\n",
      "data/train\\raw_text\\952.txt successfully read and tokenized\n",
      "49\n",
      "Failed at splitting tokens from file data/train\\raw_text\\952.txt into examples\n",
      "data/train\\raw_text\\953.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\953.txt into examples\n",
      "data/train\\raw_text\\954.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\954.txt into examples\n",
      "data/train\\raw_text\\955.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\955.txt into examples\n",
      "data/train\\raw_text\\956.txt successfully read and tokenized\n",
      "64\n",
      "Failed at splitting tokens from file data/train\\raw_text\\956.txt into examples\n",
      "data/train\\raw_text\\957.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\957.txt into examples\n",
      "data/train\\raw_text\\958.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\958.txt into examples\n",
      "data/train\\raw_text\\959.txt successfully read and tokenized\n",
      "46\n",
      "Failed at splitting tokens from file data/train\\raw_text\\959.txt into examples\n",
      "data/train\\raw_text\\96.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\96.txt into examples\n",
      "data/train\\raw_text\\960.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\960.txt into examples\n",
      "data/train\\raw_text\\961.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\961.txt into examples\n",
      "data/train\\raw_text\\962.txt successfully read and tokenized\n",
      "66\n",
      "Failed at splitting tokens from file data/train\\raw_text\\962.txt into examples\n",
      "data/train\\raw_text\\963.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\963.txt into examples\n",
      "data/train\\raw_text\\964.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\964.txt into examples\n",
      "data/train\\raw_text\\965.txt successfully read and tokenized\n",
      "50\n",
      "Failed at splitting tokens from file data/train\\raw_text\\965.txt into examples\n",
      "data/train\\raw_text\\966.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\966.txt into examples\n",
      "data/train\\raw_text\\967.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\967.txt into examples\n",
      "data/train\\raw_text\\968.txt successfully read and tokenized\n",
      "69\n",
      "Failed at splitting tokens from file data/train\\raw_text\\968.txt into examples\n",
      "data/train\\raw_text\\969.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\969.txt into examples\n",
      "data/train\\raw_text\\97.txt successfully read and tokenized\n",
      "56\n",
      "Failed at splitting tokens from file data/train\\raw_text\\97.txt into examples\n",
      "data/train\\raw_text\\970.txt successfully read and tokenized\n",
      "81\n",
      "Failed at splitting tokens from file data/train\\raw_text\\970.txt into examples\n",
      "data/train\\raw_text\\971.txt successfully read and tokenized\n",
      "71\n",
      "Failed at splitting tokens from file data/train\\raw_text\\971.txt into examples\n",
      "data/train\\raw_text\\972.txt successfully read and tokenized\n",
      "75\n",
      "Failed at splitting tokens from file data/train\\raw_text\\972.txt into examples\n",
      "data/train\\raw_text\\973.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\973.txt into examples\n",
      "data/train\\raw_text\\974.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\974.txt into examples\n",
      "data/train\\raw_text\\975.txt successfully read and tokenized\n",
      "51\n",
      "Failed at splitting tokens from file data/train\\raw_text\\975.txt into examples\n",
      "data/train\\raw_text\\976.txt successfully read and tokenized\n",
      "73\n",
      "Failed at splitting tokens from file data/train\\raw_text\\976.txt into examples\n",
      "data/train\\raw_text\\977.txt successfully read and tokenized\n",
      "45\n",
      "Failed at splitting tokens from file data/train\\raw_text\\977.txt into examples\n",
      "data/train\\raw_text\\978.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\978.txt into examples\n",
      "data/train\\raw_text\\979.txt successfully read and tokenized\n",
      "36\n",
      "Failed at splitting tokens from file data/train\\raw_text\\979.txt into examples\n",
      "data/train\\raw_text\\98.txt successfully read and tokenized\n",
      "58\n",
      "Failed at splitting tokens from file data/train\\raw_text\\98.txt into examples\n",
      "data/train\\raw_text\\980.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\980.txt into examples\n",
      "data/train\\raw_text\\981.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\981.txt into examples\n",
      "data/train\\raw_text\\982.txt successfully read and tokenized\n",
      "57\n",
      "Failed at splitting tokens from file data/train\\raw_text\\982.txt into examples\n",
      "data/train\\raw_text\\983.txt successfully read and tokenized\n",
      "40\n",
      "Failed at splitting tokens from file data/train\\raw_text\\983.txt into examples\n",
      "data/train\\raw_text\\984.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\984.txt into examples\n",
      "data/train\\raw_text\\985.txt successfully read and tokenized\n",
      "52\n",
      "Failed at splitting tokens from file data/train\\raw_text\\985.txt into examples\n",
      "data/train\\raw_text\\986.txt successfully read and tokenized\n",
      "67\n",
      "Failed at splitting tokens from file data/train\\raw_text\\986.txt into examples\n",
      "data/train\\raw_text\\987.txt successfully read and tokenized\n",
      "59\n",
      "Failed at splitting tokens from file data/train\\raw_text\\987.txt into examples\n",
      "data/train\\raw_text\\988.txt successfully read and tokenized\n",
      "61\n",
      "Failed at splitting tokens from file data/train\\raw_text\\988.txt into examples\n",
      "data/train\\raw_text\\989.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\989.txt into examples\n",
      "data/train\\raw_text\\99.txt successfully read and tokenized\n",
      "55\n",
      "Failed at splitting tokens from file data/train\\raw_text\\99.txt into examples\n",
      "data/train\\raw_text\\990.txt successfully read and tokenized\n",
      "37\n",
      "Failed at splitting tokens from file data/train\\raw_text\\990.txt into examples\n",
      "data/train\\raw_text\\991.txt successfully read and tokenized\n",
      "63\n",
      "Failed at splitting tokens from file data/train\\raw_text\\991.txt into examples\n",
      "data/train\\raw_text\\992.txt successfully read and tokenized\n",
      "68\n",
      "Failed at splitting tokens from file data/train\\raw_text\\992.txt into examples\n",
      "data/train\\raw_text\\993.txt successfully read and tokenized\n",
      "47\n",
      "Failed at splitting tokens from file data/train\\raw_text\\993.txt into examples\n",
      "data/train\\raw_text\\994.txt successfully read and tokenized\n",
      "54\n",
      "Failed at splitting tokens from file data/train\\raw_text\\994.txt into examples\n",
      "data/train\\raw_text\\995.txt successfully read and tokenized\n",
      "60\n",
      "Failed at splitting tokens from file data/train\\raw_text\\995.txt into examples\n",
      "data/train\\raw_text\\996.txt successfully read and tokenized\n",
      "53\n",
      "Failed at splitting tokens from file data/train\\raw_text\\996.txt into examples\n",
      "data/train\\raw_text\\997.txt successfully read and tokenized\n",
      "38\n",
      "Failed at splitting tokens from file data/train\\raw_text\\997.txt into examples\n",
      "data/train\\raw_text\\998.txt successfully read and tokenized\n",
      "65\n",
      "Failed at splitting tokens from file data/train\\raw_text\\998.txt into examples\n",
      "data/train\\raw_text\\999.txt successfully read and tokenized\n",
      "48\n",
      "Failed at splitting tokens from file data/train\\raw_text\\999.txt into examples\n",
      "0 examples total tokenized\n",
      "0 examples created and saved in data/train\\tokenized_examples\\examples_gpt2_blocksize_0_train.pkl\n"
     ]
    }
   ],
   "source": [
    "make_tokenized_examples(gpt2_tokenizer,10, train_path, examples_file=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryData(torch.utils.data.Dataset):\n",
    "    '''This is a class for loading in a list of tokenized gpt2 examples from a list of file paths'''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            file_paths: list):\n",
    "\n",
    "        for fpath in file_paths:\n",
    "            assert os.path.isfile(fpath), \"{} does not exist\".format(fpath)\n",
    "\n",
    "        self.examples = []\n",
    "\n",
    "        for fpath in file_paths:\n",
    "            with open(fpath, 'rb') as f:\n",
    "                examps = pickle.load(f)\n",
    "            self.examples.extend(examps)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.examples[item], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/tokenized_examples/examples_gpt2_blocksize_256_train.pkl']\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "file_paths.append(os.path.join('data/train/', \"tokenized_examples/examples_gpt2_blocksize_10_train.pkl\"))\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the actual instance of the Dataset class using the chosen authors \n",
    "story_dataset = StoryData(file_paths)\n",
    "\n",
    "# make the data loader\n",
    "#NOTE: the batch_size is 1 because we will be doing gradient accumulation. This is to get around the fact\n",
    "# that I am using a 8GB RTX 2070 Super GPU which is small\n",
    "story_dataloader = DataLoader(story_dataset, batch_size =1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 762/762 [00:00<00:00, 191kB/s]\n",
      "Downloading: 100%|██████████| 353M/353M [00:42<00:00, 8.21MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Pick a model to train\n",
    "\n",
    "# distilgpt2 will on my 8GB GPU\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "\n",
    "# gpt2-medium will not train on an 8GB GPU ... but you can generate text with the pre-trained model if you like.\n",
    "# if you have a larger GPU, say a 24 GB RTX 3090 you may wish to try training though\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "\n",
    "# NOTE: look into gradient checkpointing and see if that will allow for training within 8GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set epochs and batch size\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 8 # note we are actually going to use gradient accumulation because these models are so big\n",
    "\n",
    "# for the scheduler\n",
    "LEARNING_RATE = 0.0001 #0.00002\n",
    "WARMUP_STEPS = 100 # 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the model on the gpu. note if this doesn't say you're using the gpu this will not train!\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('using gpu')\n",
    "    device = 'cuda'\n",
    "print('device:',device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# make scheduler (for varying learning rate over time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function to generate text from the model\n",
    "\n",
    "def generate_test_text(model, max_length=256, input_text=None):\n",
    "    model.eval() # put the model in eval mode\n",
    "    if input_text is None:\n",
    "        input_text = \"Once upon a time there was a little mouse.\"\n",
    "    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='pt')\n",
    "    input_ids = input_ids.to('cuda')\n",
    "    output_ids = model.generate(input_ids, \n",
    "                                pad_token_id=gpt2_tokenizer.eos_token_id,\n",
    "                                max_length=max_length, \n",
    "                                do_sample=True, \n",
    "                                top_p=0.95, \n",
    "                                top_k=60,\n",
    "                                num_return_sequences=1)\n",
    "\n",
    "    output_text = gpt2_tokenizer.decode(output_ids[0])\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and do some generation. The output should be different every time you run this cell \n",
    "# and of all sorts of topics and styles\n",
    "prompt =\"once upon a time there was a little mouse\" \n",
    "print(generate_test_text(model,input_text=prompt, max_length=256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the link to the gradient accumulation documentation\n",
    "# https://pytorch.org/docs/stable/notes/amp_examples.html#gradient-accumulation# \n",
    "\n",
    "#TODO: look into gradient checkpointing as well\n",
    "\n",
    "epoch_loss = 0.0 # used to track loss for each epoch\n",
    "\n",
    "internal_batch_count = 0 # used to track number of examples within each batch. This is necessary \n",
    "                         # because of the gradient accumulation hack (to deal with my 8GB GPU memory)\n",
    "    \n",
    "# make FP16 scaler for faster training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "# put the model into training mode\n",
    "model.train()\n",
    "\n",
    "for epoch in range(N_EPOCHS): # iterate over epochs\n",
    "    \n",
    "    print(\"started epoch {}\".format(epoch))\n",
    "    \n",
    "    for idx, text in enumerate(story_dataloader):  # this data loader is set up to shuffle automatically\n",
    "\n",
    "        # Do the forward propagation. \n",
    "        # Don't forget to put the text onto the gpu.\n",
    "        # you have to put in labels to get the loss as an output.\n",
    "        # because GPT is an autogregessive model the input is the output for training purposes\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(text.to(device), labels=(text.to(device)))\n",
    "        \n",
    "            # get the loss out so we can do backwards propagation\n",
    "            loss, logits = outputs[:2]\n",
    "            loss = loss / BATCH_SIZE \n",
    "        \n",
    "        # do backpropagation. yay autodifferentiation!\n",
    "        # note the use of the scaler for the FP16 \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # keep track of the loss\n",
    "        epoch_loss = epoch_loss + loss.detach().cpu().numpy()  # need to detach the gradients \n",
    "                                                               # because we only care about the numerical value\n",
    "                                                               # also store the epoch loss on the cpu as numpy\n",
    "            \n",
    "        # increment the internal_batch_count\n",
    "        internal_batch_count = internal_batch_count + 1\n",
    "        \n",
    "        # Now, if we have run through a full batch, take some optimizer and gradient steps\n",
    "        if internal_batch_count == BATCH_SIZE:\n",
    "            internal_batch_count = 0 # reset this\n",
    "            \n",
    "            # take an optimizer step. note the use of the scaler for FP16\n",
    "            scaler.step(optimizer) \n",
    "            scaler.update()\n",
    "            optimizer.zero_grad() # zero out the gradients in the optimizer\n",
    "            \n",
    "            model.zero_grad() # zero out the gradients we've been accumulating in the model\n",
    "            \n",
    "            scheduler.step() # take a scheduler step\n",
    "\n",
    "     # Now that we've gone through an epoch, let's see what the loss is and what some generated text looks like\n",
    "    \n",
    "    # put the model into evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # print the loss\n",
    "    print(\"Epoch {} has loss {}\".format(epoch, epoch_loss))\n",
    "    # reset the loss\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # uncomment this if you want to print some test text after each epoch\n",
    "    #print(generate_test_text(model,input_text=prompt))\n",
    "    \n",
    "    \n",
    "    # put the model back in training mode\n",
    "    model.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Story after finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a prompt\n",
    "prompt =\"Once upon a time there was a little mouse\" \n",
    "\n",
    "# And generate text!\n",
    "print(generate_test_text(model,input_text=prompt, max_length=256))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a5386850cfb9fa7c80b45611d4d4fe5cb8e2c707cacd825b30bedc7efa209b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
