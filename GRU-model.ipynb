{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Story Generation using GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = pd.read_csv(\"story_generation_dataset/ROCStories_train.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyid</th>\n",
       "      <th>storytitle</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>sentence5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd</td>\n",
       "      <td>David Drops the Weight</td>\n",
       "      <td>David noticed he had put on a lot of weight re...</td>\n",
       "      <td>He examined his habits to try and figure out t...</td>\n",
       "      <td>He realized he'd been eating too much fast foo...</td>\n",
       "      <td>He stopped going to burger places and started ...</td>\n",
       "      <td>After a few weeks, he started to feel much bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0beabab2-fb49-460e-a6e6-f35a202e3348</td>\n",
       "      <td>Frustration</td>\n",
       "      <td>Tom had a very short temper.</td>\n",
       "      <td>One day a guest made him very angry.</td>\n",
       "      <td>He punched a hole in the wall of his house.</td>\n",
       "      <td>Tom's guest became afraid and left quickly.</td>\n",
       "      <td>Tom sat on his couch filled with regret about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87da1a22-df0b-410c-b186-439700b70ba6</td>\n",
       "      <td>Marcus Buys Khakis</td>\n",
       "      <td>Marcus needed clothing for a business casual e...</td>\n",
       "      <td>All of his clothes were either too formal or t...</td>\n",
       "      <td>He decided to buy a pair of khakis.</td>\n",
       "      <td>The pair he bought fit him perfectly.</td>\n",
       "      <td>Marcus was happy to have the right clothes for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9</td>\n",
       "      <td>Different Opinions</td>\n",
       "      <td>Bobby thought Bill should buy a trailer and ha...</td>\n",
       "      <td>Bill thought a truck would be better for what ...</td>\n",
       "      <td>Bobby pointed out two vehicles were much more ...</td>\n",
       "      <td>Bill was set in his ways with conventional thi...</td>\n",
       "      <td>He ended up buying the truck he wanted despite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c71bb23b-7731-4233-8298-76ba6886cee1</td>\n",
       "      <td>Overcoming shortcomings</td>\n",
       "      <td>John was a pastor with a very bad memory.</td>\n",
       "      <td>He tried to memorize his sermons many days in ...</td>\n",
       "      <td>He decided to learn to sing to overcome his ha...</td>\n",
       "      <td>He then made all his sermons into music and sa...</td>\n",
       "      <td>His congregation was delighted and so was he.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                storyid               storytitle  \\\n",
       "0  8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd   David Drops the Weight   \n",
       "1  0beabab2-fb49-460e-a6e6-f35a202e3348              Frustration   \n",
       "2  87da1a22-df0b-410c-b186-439700b70ba6       Marcus Buys Khakis   \n",
       "3  2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9       Different Opinions   \n",
       "4  c71bb23b-7731-4233-8298-76ba6886cee1  Overcoming shortcomings   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  David noticed he had put on a lot of weight re...   \n",
       "1                       Tom had a very short temper.   \n",
       "2  Marcus needed clothing for a business casual e...   \n",
       "3  Bobby thought Bill should buy a trailer and ha...   \n",
       "4          John was a pastor with a very bad memory.   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  He examined his habits to try and figure out t...   \n",
       "1               One day a guest made him very angry.   \n",
       "2  All of his clothes were either too formal or t...   \n",
       "3  Bill thought a truck would be better for what ...   \n",
       "4  He tried to memorize his sermons many days in ...   \n",
       "\n",
       "                                           sentence3  \\\n",
       "0  He realized he'd been eating too much fast foo...   \n",
       "1        He punched a hole in the wall of his house.   \n",
       "2                He decided to buy a pair of khakis.   \n",
       "3  Bobby pointed out two vehicles were much more ...   \n",
       "4  He decided to learn to sing to overcome his ha...   \n",
       "\n",
       "                                           sentence4  \\\n",
       "0  He stopped going to burger places and started ...   \n",
       "1        Tom's guest became afraid and left quickly.   \n",
       "2              The pair he bought fit him perfectly.   \n",
       "3  Bill was set in his ways with conventional thi...   \n",
       "4  He then made all his sermons into music and sa...   \n",
       "\n",
       "                                           sentence5  \n",
       "0  After a few weeks, he started to feel much bet...  \n",
       "1  Tom sat on his couch filled with regret about ...  \n",
       "2  Marcus was happy to have the right clothes for...  \n",
       "3  He ended up buying the truck he wanted despite...  \n",
       "4      His congregation was delighted and so was he.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "array = stories.values[:,2:].reshape(-1).tolist()\n",
    "print(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['david', 'noticed', 'he', 'had', 'put', 'on', 'a', 'lot', 'of', 'weight', 'recently'], ['he', 'examined', 'his', 'habits', 'to', 'try', 'and', 'figure', 'out', 'the', 'reason'], ['he', 'realized', \"he'd\", 'been', 'eating', 'too', 'much', 'fast', 'food', 'lately'], ['he', 'stopped', 'going', 'to', 'burger', 'places', 'and', 'started', 'a', 'vegetarian', 'diet'], ['after', 'a', 'few', 'weeks,', 'he', 'started', 'to', 'feel', 'much', 'better'], ['tom', 'had', 'a', 'very', 'short', 'temper'], ['one', 'day', 'a', 'guest', 'made', 'him', 'very', 'angry'], ['he', 'punched', 'a', 'hole', 'in', 'the', 'wall', 'of', 'his', 'house'], [\"tom's\", 'guest', 'became', 'afraid', 'and', 'left', 'quickly'], ['tom', 'sat', 'on', 'his', 'couch', 'filled', 'with', 'regret', 'about', 'his', 'actions']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization of each document\n",
    "tokenized_doc = []\n",
    "sent_ls=[]\n",
    "for sent in array:\n",
    "    sent_ls=[]\n",
    "    for w in sent.split(' '):\n",
    "        w = w.lower().replace('.','')\n",
    "        sent_ls.append(w)\n",
    "    tokenized_doc.append(sent_ls)\n",
    "\n",
    "print(tokenized_doc[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['david', 'noticed', 'he', 'had', 'put', 'on', 'a', 'lot', 'of', 'weight', 'recently'], tags=[0]),\n",
       " TaggedDocument(words=['he', 'examined', 'his', 'habits', 'to', 'try', 'and', 'figure', 'out', 'the', 'reason'], tags=[1]),\n",
       " TaggedDocument(words=['he', 'realized', \"he'd\", 'been', 'eating', 'too', 'much', 'fast', 'food', 'lately'], tags=[2]),\n",
       " TaggedDocument(words=['he', 'stopped', 'going', 'to', 'burger', 'places', 'and', 'started', 'a', 'vegetarian', 'diet'], tags=[3]),\n",
       " TaggedDocument(words=['after', 'a', 'few', 'weeks,', 'he', 'started', 'to', 'feel', 'much', 'better'], tags=[4]),\n",
       " TaggedDocument(words=['tom', 'had', 'a', 'very', 'short', 'temper'], tags=[5]),\n",
       " TaggedDocument(words=['one', 'day', 'a', 'guest', 'made', 'him', 'very', 'angry'], tags=[6]),\n",
       " TaggedDocument(words=['he', 'punched', 'a', 'hole', 'in', 'the', 'wall', 'of', 'his', 'house'], tags=[7]),\n",
       " TaggedDocument(words=[\"tom's\", 'guest', 'became', 'afraid', 'and', 'left', 'quickly'], tags=[8]),\n",
       " TaggedDocument(words=['tom', 'sat', 'on', 'his', 'couch', 'filled', 'with', 'regret', 'about', 'his', 'actions'], tags=[9])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tokenized document into gensim formated tagged data\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "tagged_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train doc2vec model\n",
    "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 100)\n",
    "# Save trained doc2vec model\n",
    "model.save(\"test_doc2vec.model\")\n",
    "## Load saved doc2vec model\n",
    "model= Doc2Vec.load(\"test_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyid</th>\n",
       "      <th>storytitle</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>sentence5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a34dd5ad-761f-4369-acaf-42e146479c9b</td>\n",
       "      <td>Bad Dream</td>\n",
       "      <td>Tommy was very close to his dad and loved him ...</td>\n",
       "      <td>His was a cop and was shot and killed on duty.</td>\n",
       "      <td>Tommy cried in his mother's arms at the funeral.</td>\n",
       "      <td>Tommy suddenly woke up in a cold sweat.</td>\n",
       "      <td>Realizing he had just had a bad dream, he went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d14fc434-01da-4b39-9e7b-3733c510ac29</td>\n",
       "      <td>Scary Movies</td>\n",
       "      <td>Tim was dating a girl who was easily scared.</td>\n",
       "      <td>He decided to have a horror movie night.</td>\n",
       "      <td>She reluctantly agreed.</td>\n",
       "      <td>Tim's girlfriend was scared and stayed close t...</td>\n",
       "      <td>Tim's plan worked perfectly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56800cdf-d149-489f-9ee4-a87ea3138533</td>\n",
       "      <td>Red Butterfly</td>\n",
       "      <td>Samuel collected butterflies for his collection.</td>\n",
       "      <td>One afternoon he spotted a bright red butterfly.</td>\n",
       "      <td>He tried to catch it but it kept flying higher.</td>\n",
       "      <td>Samuel got a ladder and went to the roof of hi...</td>\n",
       "      <td>He missed his footing and went tumbling off th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ba922c2-afe4-444f-a9b7-8bcf202ebf65</td>\n",
       "      <td>Dirty Feet</td>\n",
       "      <td>She ran outside without her shoes.</td>\n",
       "      <td>She was excited to catch the ice cream man.</td>\n",
       "      <td>She ordered her ice cream and ran home.</td>\n",
       "      <td>She ran into the house.</td>\n",
       "      <td>Her mother yelled because her feet were dirty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f81f29cd-b6f4-4faf-af9a-b779787a6b34</td>\n",
       "      <td>Bullfrog</td>\n",
       "      <td>There once was a man named Larry Butterfrog.</td>\n",
       "      <td>He went down to buy World of Warcraft.</td>\n",
       "      <td>However, he lacked the money.</td>\n",
       "      <td>So, he had to go to his mom, who was miffed.</td>\n",
       "      <td>And she told him to get a job.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                storyid     storytitle  \\\n",
       "0  a34dd5ad-761f-4369-acaf-42e146479c9b      Bad Dream   \n",
       "1  d14fc434-01da-4b39-9e7b-3733c510ac29   Scary Movies   \n",
       "2  56800cdf-d149-489f-9ee4-a87ea3138533  Red Butterfly   \n",
       "3  0ba922c2-afe4-444f-a9b7-8bcf202ebf65     Dirty Feet   \n",
       "4  f81f29cd-b6f4-4faf-af9a-b779787a6b34       Bullfrog   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  Tommy was very close to his dad and loved him ...   \n",
       "1       Tim was dating a girl who was easily scared.   \n",
       "2   Samuel collected butterflies for his collection.   \n",
       "3                 She ran outside without her shoes.   \n",
       "4       There once was a man named Larry Butterfrog.   \n",
       "\n",
       "                                          sentence2  \\\n",
       "0    His was a cop and was shot and killed on duty.   \n",
       "1          He decided to have a horror movie night.   \n",
       "2  One afternoon he spotted a bright red butterfly.   \n",
       "3       She was excited to catch the ice cream man.   \n",
       "4            He went down to buy World of Warcraft.   \n",
       "\n",
       "                                          sentence3  \\\n",
       "0  Tommy cried in his mother's arms at the funeral.   \n",
       "1                           She reluctantly agreed.   \n",
       "2   He tried to catch it but it kept flying higher.   \n",
       "3           She ordered her ice cream and ran home.   \n",
       "4                     However, he lacked the money.   \n",
       "\n",
       "                                           sentence4  \\\n",
       "0            Tommy suddenly woke up in a cold sweat.   \n",
       "1  Tim's girlfriend was scared and stayed close t...   \n",
       "2  Samuel got a ladder and went to the roof of hi...   \n",
       "3                            She ran into the house.   \n",
       "4       So, he had to go to his mom, who was miffed.   \n",
       "\n",
       "                                           sentence5  \n",
       "0  Realizing he had just had a bad dream, he went...  \n",
       "1                       Tim's plan worked perfectly.  \n",
       "2  He missed his footing and went tumbling off th...  \n",
       "3     Her mother yelled because her feet were dirty.  \n",
       "4                     And she told him to get a job.  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stories = pd.read_csv(\"story_generation_dataset/ROCStories_test.csv\", encoding=\"utf8\")\n",
    "test_stories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(test_stories.values.shape)\n",
    "test_array = test_stories.values[:,2:].reshape(-1).tolist()\n",
    "print(len(test_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "      tokenized_sent = []\n",
    "      for w in sent.split(' '):\n",
    "            w.lower().replace('.','')\n",
    "            tokenized_sent.append(w)\n",
    "      return tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tommy', 'was', 'very', 'close', 'to', 'his', 'dad', 'and', 'loved', 'him', 'greatly.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(149995, 0.9008253216743469),\n",
       " (432, 0.8353145122528076),\n",
       " (61706, 0.8109379410743713),\n",
       " (24838, 0.8096643686294556),\n",
       " (54473, 0.8055285811424255),\n",
       " (83629, 0.7830244898796082),\n",
       " (11907, 0.7824154496192932),\n",
       " (106179, 0.7814722657203674),\n",
       " (87761, 0.7702282667160034),\n",
       " (115938, 0.765677809715271)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find most similar doc \n",
    "test_doc = tokenize(test_array[0])\n",
    "print(test_doc)\n",
    "sim = model.docvecs.most_similar(positive=[model.infer_vector(test_doc)],topn=10)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149995, 432, 61706, 24838, 54473, 83629, 11907, 106179, 87761, 115938]\n"
     ]
    }
   ],
   "source": [
    "similar_index = []\n",
    "for tup in sim:\n",
    "      similar_index.append(tup[0])\n",
    "print(similar_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Story:\n",
      "Tommy was very close to his dad and loved him greatly.\n",
      "Generated Story:\n",
      "Tommy was very close to his dad and loved him greatly. His dad turned around and started to laugh. She grew up without a mom and was responsible for her brothers. His parents were not happy about the arrest. She enjoyed the one nurse who always joked around with her. Ariel made new friends quickly. Her mom started by teaching her how to cook rice. She was disappointed her son wasn't more like her. He always kept a flashlight with him to see ahead of him. Dan's friends eventually stopped hanging out with him. \n"
     ]
    }
   ],
   "source": [
    "txt =test_array[0]\n",
    "new_txt = \"\"\n",
    "print('Original Story:')\n",
    "print(txt)\n",
    "print('Generated Story:')\n",
    "for i in similar_index:\n",
    "      new_txt += array[i] + \" \"\n",
    "print(new_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ac869a620031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvecn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_doc2vec.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvecn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Downloads\\python3.6\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[0mfile\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mFile\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0msaved\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0munchanged\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnpy\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mextension\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mappended\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mdoes\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0malready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "n = 10 \n",
    "array = stories.values[:n,1:].reshape(-1).tolist()\n",
    "vecn = np.load(\"test_doc2vec.model\")\n",
    "vec = vecn.tolist()\n",
    "len(vec)\n",
    "\n",
    "def nn(qvec, vectors, array, k=5):\n",
    "    qvec /= np.linalg.norm(qvec)\n",
    "    vectors /= np.linalg.norm(vectors)\n",
    "    scores = np.dot(qvec, vectors.T).flatten()\n",
    "    sorted_args = np.argsort(scores)[::-1]\n",
    "    sentences = [array[a] for a in sorted_args[:k]]\n",
    "    for i, s in enumerate(sentences):\n",
    "        print (s, sorted_args[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db9c657620c8578ddfc3d9ba89c38fdc5fd80f960e156f76bd6d1a512183127c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
